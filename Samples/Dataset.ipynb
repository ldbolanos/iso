{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"../Datasets/Reviews/Electronics_5.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading json file (it's pretty dirty.)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Datasets/Reviews/Electronics_5.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-868015b1353d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mraw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loaded data into memory.\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Datasets/Reviews/Electronics_5.json'"
     ]
    }
   ],
   "source": [
    "dataset = {}\n",
    "print(\"Loading json file (it's pretty dirty.)\")\n",
    "dirty = []\n",
    "\n",
    "dist = {}\n",
    "\n",
    "with open(filepath) as raw:\n",
    "    print(\"loaded data into memory.\\n\")\n",
    "    entries = raw.read().split('\\n')\n",
    "    size = len(entries)\n",
    "    count = 0\n",
    "    for i in entries:\n",
    "        count += 1\n",
    "        try:\n",
    "            entry = json.loads(i)\n",
    "            itemID = entry['asin']\n",
    "            if itemID not in dataset:\n",
    "                dataset[itemID] = [entry]\n",
    "                dist[itemID] = 1\n",
    "            else:\n",
    "                dataset[itemID].append(entry)\n",
    "                dist[itemID] += 1\n",
    "            \n",
    "        except:\n",
    "            dirty.append(i)\n",
    "            \n",
    "        msg = \"Loaded \" + str((count/size)*100) + \"\\r\"\n",
    "        print(msg, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "prods = 0\n",
    "for key in dist:\n",
    "    prods += 1\n",
    "    ent = dist[key]\n",
    "    total += ent\n",
    "print(\"total:\",total)\n",
    "print(\"products:\", prods)\n",
    "print(\"mean:\", total/prods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distributions = []\n",
    "for key in dist:\n",
    "    distributions.append(dist[key])\n",
    "distributions = sorted(distributions)\n",
    "distributions = np.array(distributions)\n",
    "print(distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = distributions[::2].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.linspace(1,d.size, d.size, dtype = int)\n",
    "plt.hist(ids, d)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = list(dataset.keys())\n",
    "for r in dataset[k[0]]:\n",
    "#     print(r['reviewText']+\"\\n\")\n",
    "    print(r)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickleFile = '../Datasets/Reviews/dataset.pkl'\n",
    "\n",
    "output = open(pickleFile, 'wb')\n",
    "\n",
    "pickle.dump(dataset, output)\n",
    "\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll try and reload the pickle file we created; this will be easier to use since it's already preprocessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickleFile = '../Datasets/Reviews/dataset.pkl'\n",
    "start = time.clock()\n",
    "wow = pickle.load( open( pickleFile, \"rb\" ))\n",
    "duration = time.clock() - start\n",
    "print(duration, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in wow:\n",
    "    print(i, wow[i])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also have the dataset stored on a network drive, so I want to see how fast it takes to load that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remoteFile = '/media/t/drobo/Thien/Datasets/iso/Reviews/dataset.pkl'\n",
    "\n",
    "start = time.clock()\n",
    "wow = pickle.load( open( remoteFile, \"rb\" ))\n",
    "duration = time.clock() - start\n",
    "print(duration, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
