{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "# use Matplotlib (don't ask)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baby's first Autoencoder\n",
    "\n",
    "We'll start simple, with a single fully-connected neural layer as encoder and as decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# this is the size of our encoded representations\n",
    "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(784,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also create a separate encoder model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also make a decoder model here too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train our autoencoder to reconstruct MNIST digits.\n",
    "\n",
    "First, we'll configure our model to use a per-pixel binary crossentropy loss, and the Adadelta optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare our input data. We're using MNIST digits, and we're discarding the labels (since we're only interested in encoding/decoding the input images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll normalise all the values between 0 and 1, and we'll flatten the 28x28 images into vectors of size 784 (by concatenation of the rows.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print (x_train.shape)\n",
    "print (x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll train the autoencoder for 50 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.3677 - val_loss: 0.2715\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2641 - val_loss: 0.2525\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2418 - val_loss: 0.2289\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2219 - val_loss: 0.2123\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2077 - val_loss: 0.2003\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1970 - val_loss: 0.1911\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1886 - val_loss: 0.1836\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1818 - val_loss: 0.1774\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1762 - val_loss: 0.1723\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1712 - val_loss: 0.1677\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1667 - val_loss: 0.1633\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1624 - val_loss: 0.1590\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1584 - val_loss: 0.1551\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1546 - val_loss: 0.1515\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1510 - val_loss: 0.1480\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1478 - val_loss: 0.1449\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1448 - val_loss: 0.1421\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1420 - val_loss: 0.1393\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1395 - val_loss: 0.1368\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1370 - val_loss: 0.1344\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1347 - val_loss: 0.1322\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1326 - val_loss: 0.1301\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1305 - val_loss: 0.1280\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1286 - val_loss: 0.1263\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1268 - val_loss: 0.1245\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1251 - val_loss: 0.1228\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1235 - val_loss: 0.1212\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1220 - val_loss: 0.1198\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1206 - val_loss: 0.1184\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1193 - val_loss: 0.1172\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1181 - val_loss: 0.1160\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1170 - val_loss: 0.1149\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1159 - val_loss: 0.1138\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1150 - val_loss: 0.1129\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1140 - val_loss: 0.1120\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1132 - val_loss: 0.1112\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1124 - val_loss: 0.1103\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1116 - val_loss: 0.1096\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1109 - val_loss: 0.1089\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1103 - val_loss: 0.1083\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1097 - val_loss: 0.1077\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1091 - val_loss: 0.1072\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1086 - val_loss: 0.1067\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1081 - val_loss: 0.1062\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1077 - val_loss: 0.1058\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1072 - val_loss: 0.1053\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1068 - val_loss: 0.1049\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1065 - val_loss: 0.1046\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1061 - val_loss: 0.1043\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1058 - val_loss: 0.1039\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd68a617940>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 50 epochs, the autoencoder seems to reach a stable train/test loss value of about 0.11. We can try to visualize the reconstructed inputs and the encoded representations. We will use Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and decode some digits\n",
    "# note that we take them from the *test* set\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.1447687"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_imgs.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a Sparsity Constraint on encoded representations\n",
    "\n",
    "In the previous example, the representations were only constrained by the size of the hidden layer (32). In such a situation, what typically happens is that the hidden layer is learning an approximation of PCA (principal component analysis). But another way to constrain the representations to be compact is to add a sparsity contraint on the activity of the hidden representations, so fewer units would \"fire\" at a given time. In Keras, this can be done by adding an `activity_regularizer` to our Dense layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "encoding_dim = 32\n",
    "\n",
    "input_img = Input(shape=(784,))\n",
    "# add a Dense layer with a L1 activity regularizer\n",
    "encoded = Dense(encoding_dim, activation='relu',\n",
    "                activity_regularizer=regularizers.l1(10e-5))(input_img)\n",
    "decoded = Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "autoencoder = Model(input_img, decoded)\n",
    "\n",
    "\n",
    "encoder = Model(input_img, encoded)\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll train this model for 100 epochs with the regulariser included. This will make the model less prone to overfitting; it can also be trained for longer. We'll visualise the results while we're at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.6736 - val_loss: 0.6485\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.6284 - val_loss: 0.6090\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.5916 - val_loss: 0.5749\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.5598 - val_loss: 0.5454\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.5323 - val_loss: 0.5198\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.5084 - val_loss: 0.4975\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.4875 - val_loss: 0.4780\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.4692 - val_loss: 0.4609\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.4531 - val_loss: 0.4457\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.4389 - val_loss: 0.4324\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.4262 - val_loss: 0.4205\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.4150 - val_loss: 0.4098\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.4049 - val_loss: 0.4003\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.3959 - val_loss: 0.3918\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.3877 - val_loss: 0.3840\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.3804 - val_loss: 0.3771\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3737 - val_loss: 0.3707\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.3676 - val_loss: 0.3649\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.3621 - val_loss: 0.3596\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.3570 - val_loss: 0.3548\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.3524 - val_loss: 0.3503\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.3481 - val_loss: 0.3463\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.3442 - val_loss: 0.3425\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.3406 - val_loss: 0.3390\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.3372 - val_loss: 0.3357\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.3341 - val_loss: 0.3327\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.3312 - val_loss: 0.3299\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.3285 - val_loss: 0.3273\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3259 - val_loss: 0.3249\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.3236 - val_loss: 0.3226\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.3214 - val_loss: 0.3204\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3193 - val_loss: 0.3184\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.3173 - val_loss: 0.3165\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3155 - val_loss: 0.3147\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.3138 - val_loss: 0.3131\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.3121 - val_loss: 0.3115\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.3106 - val_loss: 0.3100\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.3091 - val_loss: 0.3085\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.3077 - val_loss: 0.3072\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3064 - val_loss: 0.3059\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.3052 - val_loss: 0.3047\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.3040 - val_loss: 0.3035\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3029 - val_loss: 0.3024\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.3018 - val_loss: 0.3014\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3008 - val_loss: 0.3004\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2998 - val_loss: 0.2994\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2989 - val_loss: 0.2985\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2980 - val_loss: 0.2976\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2971 - val_loss: 0.2968\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2963 - val_loss: 0.2960\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2955 - val_loss: 0.2952\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2948 - val_loss: 0.2945\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2941 - val_loss: 0.2938\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2934 - val_loss: 0.2931\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2927 - val_loss: 0.2925\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2921 - val_loss: 0.2918\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2915 - val_loss: 0.2912\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2909 - val_loss: 0.2906\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2903 - val_loss: 0.2901\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2898 - val_loss: 0.2895\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2892 - val_loss: 0.2890\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2887 - val_loss: 0.2885\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2882 - val_loss: 0.2880\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2877 - val_loss: 0.2875\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2873 - val_loss: 0.2871\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2868 - val_loss: 0.2867\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2864 - val_loss: 0.2862\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2860 - val_loss: 0.2858\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2856 - val_loss: 0.2854\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2852 - val_loss: 0.2850\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2848 - val_loss: 0.2846\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2844 - val_loss: 0.2843\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2841 - val_loss: 0.2839\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2837 - val_loss: 0.2836\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2834 - val_loss: 0.2832\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2831 - val_loss: 0.2829\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2828 - val_loss: 0.2826\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2825 - val_loss: 0.2823\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2822 - val_loss: 0.2820\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2819 - val_loss: 0.2817\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2816 - val_loss: 0.2814\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2813 - val_loss: 0.2812\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2810 - val_loss: 0.2809\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2808 - val_loss: 0.2806\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2805 - val_loss: 0.2804\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2803 - val_loss: 0.2801\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2800 - val_loss: 0.2799\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2798 - val_loss: 0.2796\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2796 - val_loss: 0.2794\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2793 - val_loss: 0.2792\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2791 - val_loss: 0.2790\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2789 - val_loss: 0.2788\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2787 - val_loss: 0.2785\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.2785 - val_loss: 0.2783\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2783 - val_loss: 0.2781\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2781 - val_loss: 0.2779\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2779 - val_loss: 0.2778\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2777 - val_loss: 0.2776\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2775 - val_loss: 0.2774\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2774 - val_loss: 0.2772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd674027a58>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=100,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# encode and decode some digits\n",
    "# note that we take them from the *test* set\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should look similar to the previous model, but the difference should be in the sparsity of the encoded representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3924803e-06"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_imgs.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Autoencoders\n",
    "\n",
    "We do not have to limit ourselves to a single layer as encoder or decoder, we could instead use a stack of layers, such as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.3597 - val_loss: 0.2638\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.2587 - val_loss: 0.2533\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.2438 - val_loss: 0.2308\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.2260 - val_loss: 0.2214\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.2174 - val_loss: 0.2107\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.2049 - val_loss: 0.1974\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1926 - val_loss: 0.1856\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1828 - val_loss: 0.1792\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1758 - val_loss: 0.1732\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1698 - val_loss: 0.1647\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1641 - val_loss: 0.1614\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1597 - val_loss: 0.1570\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1562 - val_loss: 0.1541\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1532 - val_loss: 0.1489\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1507 - val_loss: 0.1489\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1482 - val_loss: 0.1443\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1457 - val_loss: 0.1431\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1436 - val_loss: 0.1406\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1419 - val_loss: 0.1404\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1402 - val_loss: 0.1384\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1383 - val_loss: 0.1373\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1367 - val_loss: 0.1340\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1352 - val_loss: 0.1334\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1338 - val_loss: 0.1313\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1326 - val_loss: 0.1306\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1313 - val_loss: 0.1303\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1302 - val_loss: 0.1289\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1294 - val_loss: 0.1283\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1284 - val_loss: 0.1252\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1276 - val_loss: 0.1255\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1267 - val_loss: 0.1244\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1259 - val_loss: 0.1242\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1250 - val_loss: 0.1229\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1242 - val_loss: 0.1228\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1234 - val_loss: 0.1219\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1226 - val_loss: 0.1196\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1218 - val_loss: 0.1216\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1212 - val_loss: 0.1184\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1205 - val_loss: 0.1186\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1199 - val_loss: 0.1179\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1193 - val_loss: 0.1181\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1189 - val_loss: 0.1169\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1183 - val_loss: 0.1172\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1179 - val_loss: 0.1167\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1173 - val_loss: 0.1149\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1168 - val_loss: 0.1152\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1164 - val_loss: 0.1155\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1160 - val_loss: 0.1142\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1156 - val_loss: 0.1128\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1151 - val_loss: 0.1137\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1147 - val_loss: 0.1120\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1143 - val_loss: 0.1148\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1139 - val_loss: 0.1127\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1135 - val_loss: 0.1120\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1131 - val_loss: 0.1119\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1128 - val_loss: 0.1121\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1125 - val_loss: 0.1104\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1120 - val_loss: 0.1112\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1117 - val_loss: 0.1088\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1113 - val_loss: 0.1112\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1110 - val_loss: 0.1110\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1107 - val_loss: 0.1094\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1103 - val_loss: 0.1085\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1100 - val_loss: 0.1100\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1098 - val_loss: 0.1083\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1094 - val_loss: 0.1091\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1091 - val_loss: 0.1077\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1087 - val_loss: 0.1074\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1084 - val_loss: 0.1078\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1082 - val_loss: 0.1076\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1079 - val_loss: 0.1074\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1076 - val_loss: 0.1062\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1074 - val_loss: 0.1070\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1070 - val_loss: 0.1069\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1069 - val_loss: 0.1051\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1066 - val_loss: 0.1065\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1064 - val_loss: 0.1054\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1062 - val_loss: 0.1062\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1060 - val_loss: 0.1044\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1058 - val_loss: 0.1046\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1055 - val_loss: 0.1036\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1053 - val_loss: 0.1060\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1052 - val_loss: 0.1035\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1051 - val_loss: 0.1033\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1047 - val_loss: 0.1050\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1047 - val_loss: 0.1036\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1045 - val_loss: 0.1030\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1043 - val_loss: 0.1027\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1041 - val_loss: 0.1030\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1040 - val_loss: 0.1023\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1038 - val_loss: 0.1022\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1036 - val_loss: 0.1039\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1035 - val_loss: 0.1024\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1033 - val_loss: 0.1009\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1032 - val_loss: 0.1028\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1031 - val_loss: 0.1021\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1029 - val_loss: 0.1024\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1027 - val_loss: 0.1014\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1026 - val_loss: 0.1013\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1024 - val_loss: 0.1048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd6400aeba8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_img = Input(shape=(784,))\n",
    "encoded = Dense(128, activation='relu')(input_img)\n",
    "encoded = Dense(64, activation='relu')(encoded)\n",
    "encoded = Dense(32, activation='relu')(encoded)\n",
    "\n",
    "decoded = Dense(64, activation='relu')(encoded)\n",
    "decoded = Dense(128, activation='relu')(decoded)\n",
    "decoded = Dense(784, activation='sigmoid')(decoded)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=100,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 100 epochs, it reaches a train and test loss of ~0.097, a bit better than our previous models. Our reconstructed digits look a bit better too:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Autoencoders\n",
    "\n",
    "Since our inputs are images, it makes sense to use convolutional neural networks (convnets) as encoders and decoders. In practical settings, autoencoders applied to images are always convolutional autoencoders --they simply perform much better.\n",
    "\n",
    "Let's implement one. The encoder will consist in a stack of Conv2D and MaxPooling2D layers (max pooling being used for spatial down-sampling), while the decoder will consist in a stack of Conv2D and UpSampling2D layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.2203 - val_loss: 0.1754\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1618 - val_loss: 0.1527\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.1423 - val_loss: 0.1334\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1331 - val_loss: 0.1285\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.1279 - val_loss: 0.1278\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1239 - val_loss: 0.1209\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1212 - val_loss: 0.1170\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.1189 - val_loss: 0.1162\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.1169 - val_loss: 0.1155\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.1153 - val_loss: 0.1142\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1138 - val_loss: 0.1131\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.1128 - val_loss: 0.1108\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1117 - val_loss: 0.1117\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1110 - val_loss: 0.1096\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1100 - val_loss: 0.1068\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.1092 - val_loss: 0.1080\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1087 - val_loss: 0.1077\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.1081 - val_loss: 0.1070\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1076 - val_loss: 0.1092\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1069 - val_loss: 0.1027\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1004 - val_loss: 0.0995\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1004 - val_loss: 0.0971\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.0999 - val_loss: 0.0989\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1000 - val_loss: 0.0989\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.1001 - val_loss: 0.0975\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.0997 - val_loss: 0.0979\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.0997 - val_loss: 0.1001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd5ec34c400>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
