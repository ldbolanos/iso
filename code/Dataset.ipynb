{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "import gzip\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7824482/7824482 [06:05<00:00, 21417.99it/s]\n"
     ]
    }
   ],
   "source": [
    "filepath = \"../Datasets/Reviews/reviews_Electronics.json.gz\"\n",
    "\n",
    "def parse(path):\n",
    "  g = gzip.open(path, 'r')\n",
    "  for l in g:\n",
    "    yield json.dumps(eval(l))\n",
    "\n",
    "dataset = {}\n",
    "dirty = []\n",
    "size = 7824482\n",
    "\n",
    "for entry in tqdm(parse(filepath), total=size):\n",
    "    try:\n",
    "        itemID = entry['asin']\n",
    "        if itemID not in dataset:\n",
    "            dataset[itemID] = [entry]\n",
    "            dist[itemID] = 1\n",
    "        else:\n",
    "            dataset[itemID].append(entry)\n",
    "            dist[itemID] += 1\n",
    "    except:\n",
    "        dirty.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickleFile = '../Datasets/Reviews/dataset.pkl'\n",
    "output = open(pickleFile, 'wb')\n",
    "pickle.dump(dataset, output)\n",
    "output.close()\n",
    "print(\"Saved dataset to pickle file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll try and reload the pickle file we created; this will be easier to use since it's already preprocessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickleFile = '../Datasets/Reviews/dataset.pkl'\n",
    "start = time.clock()\n",
    "wow = pickle.load( open( pickleFile, \"rb\" ))\n",
    "duration = time.clock() - start\n",
    "print(duration, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in wow:\n",
    "    print(i, wow[i])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also have the dataset stored on a network drive, so I want to see how fast it takes to load that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remoteFile = '/media/t/drobo/Thien/Datasets/iso/Reviews/dataset.pkl'\n",
    "\n",
    "start = time.clock()\n",
    "wow = pickle.load( open( remoteFile, \"rb\" ))\n",
    "duration = time.clock() - start\n",
    "print(duration, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
