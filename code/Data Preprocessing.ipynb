{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import gzip\n",
    "import bcolz\n",
    "import numpy as np\n",
    "import re\n",
    "import copy\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "# seed = 1337\n",
    "# pickleFile = '../Datasets/Reviews/dataset.pkl'\n",
    "# gloveDimension = 50\n",
    "# glovePath = \"/media/data/Datasets/glove\"\n",
    "# dataset_reduction = 16\n",
    "# trainPortion = 0.80\n",
    "# vocabularyLimit = 30000\n",
    "# cutoff = 60\n",
    "# datasetFile = '../Datasets/Reviews/dataset_ready.pkl'\n",
    "# example_item_id = 19\n",
    "\n",
    "params = {\n",
    "    \"seed\" : 1337,\n",
    "    \"pickleFile\" :  '../Datasets/Reviews/dataset.pkl',\n",
    "    \"gloveDimension\" : 50,\n",
    "    \"glovePath\" : \"/media/data/Datasets/glove\",\n",
    "    \"datasetReduction\" : 16,\n",
    "    \"trainPortion\" : 0.80,\n",
    "    \"vocabularyLimit\" : 30000,\n",
    "    \"cutoff\" : 60,\n",
    "    \"datasetFile\" : '../Datasets/Reviews/dataset_ready.pkl',\n",
    "    \"example_item_id\" : 19, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(params['seed'])\n",
    "np.random.seed(params['seed'])\n",
    "\n",
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "sentencizer = nlp.create_pipe(\"sentencizer\")\n",
    "nlp.add_pipe(sentencizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the dataset in 8.81 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "dataset = pickle.load( open( params['pickleFile'], \"rb\" ))\n",
    "duration = time.clock() - start\n",
    "print(\"Loaded the dataset in\", round(duration,2), \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 63001 amazon items.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are\",len(dataset), \"amazon items.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Glove Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preloading files.. Done.\n"
     ]
    }
   ],
   "source": [
    "def loadGlove(glove_path, dim=50):\n",
    "    acceptedDimensions = [50, 100, 200, 300]\n",
    "    if dim not in acceptedDimensions:\n",
    "        print(\"You didn't choose a right dimension.\")\n",
    "        print(\"Try one of these:\", acceptedDimensions)\n",
    "        return None\n",
    "    pickleWordFile = f'{glove_path}/6B.'+str(dim)+'_words.pkl'\n",
    "    pickleIdFile   = f'{glove_path}/6B.'+str(dim)+'_idx.pkl'\n",
    "    pickleDatFile  = f'{glove_path}/glove.6B.'+str(dim)+'.dat'\n",
    "    pickleDataset  = f'{glove_path}/glove.6B.'+str(dim)+'d.txt'\n",
    "    \n",
    "    if os.path.isfile(pickleWordFile):\n",
    "        # check if we've made the outputs before\n",
    "        print(\"Preloading files..\", end=\" \")\n",
    "        vectors = bcolz.open(pickleDatFile)[:]\n",
    "        words = pickle.load(open(pickleWordFile, 'rb'))\n",
    "        word2idx = pickle.load(open(pickleIdFile, 'rb'))\n",
    "        glove = {w: vectors[word2idx[w]] for w in words}\n",
    "        print(\"Done.\")\n",
    "        return glove\n",
    "    else:\n",
    "        print(\"Doesn't work.\", end=\" \")\n",
    "\n",
    "glove = loadGlove(params['glovePath'], dim=params['gloveDimension'])\n",
    "gloveWords = glove.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove Vocabulary Size: 400000\n"
     ]
    }
   ],
   "source": [
    "print(\"Glove Vocabulary Size:\",len(gloveWords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(paragraph):\n",
    "    # split paragraph by full stops\n",
    "    paragraph = paragraph.lower()\n",
    "    paragraph = re.sub(\"([,!?()-+&Â£$.%*'])\", r' \\1 ', paragraph)\n",
    "    paragraph = re.sub('\\s{2,}', ' ', paragraph)\n",
    "    paragraph = paragraph.split(\" \")\n",
    "    # remove empty string\n",
    "    return paragraph\n",
    "    \n",
    "def discretise(value, word):\n",
    "    return word + \"_\" + str(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handleItem(itemID, dataset=dataset, printDebug=False):\n",
    "    \"\"\"\n",
    "    Filters words out based on whether they're in the GloVe dataset or not.\n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    reviews = []\n",
    "    for i in range(len(dataset[itemID])):\n",
    "        # initialise variables\n",
    "        entry = dataset[itemID][i]\n",
    "        reviewerID = entry['reviewerID']\n",
    "        \n",
    "        if len(entry['reviewText']) < 1:\n",
    "            continue\n",
    "\n",
    "        \"\"\"\n",
    "        Review Text Processing\n",
    "        \"\"\"\n",
    "\n",
    "        # spacy method\n",
    "        sentences = [list(filter(None, preprocess(str(sentence)))) for sentence in nlp(entry['reviewText']).sents]\n",
    "            \n",
    "        # preprocess summary\n",
    "        summary = list(filter(None,preprocess(entry['summary'])))\n",
    "        \n",
    "        # merge summary sequence and review sequences together into overall entries.\n",
    "        if len(sentences) < 2:\n",
    "            entries =  [[\"<sos>\", \"<summary>\"] + summary + [\"</summary>\"]] + [[\"<sos>\", \"<text>\"] + sentences[0] + [\"</text>\", \"<eor>\", \"<eos>\"]]\n",
    "        else:\n",
    "            subset = [[\"<sos>\", \"<text>\"] + x + [\"</text>\"] for x in sentences[:-1]]\n",
    "            entries =  [[\"<sos>\", \"<summary>\"] + summary + [\"</summary>\"]] + subset + [[\"<sos>\", \"<text>\"] + sentences[-1] + [\"</text>\", \"<eor>\", \"<eos>\"]]\n",
    "\n",
    "        # setup review parameters\n",
    "        rating   = [discretise(entry['overall'], \"rating\")]\n",
    "\n",
    "        # compute polarity\n",
    "        good, bad = entry['helpful'][0], entry['helpful'][1]\n",
    "        \n",
    "        try:\n",
    "            polarity = (good - bad) / (good + bad)\n",
    "        except ZeroDivisionError:\n",
    "            polarity = 0\n",
    "        polarity = np.tanh(polarity)\n",
    "        polarity = np.round(polarity, 1)\n",
    "        polarity = [discretise(polarity, \"polarity\")]\n",
    "\n",
    "        # create identity/conditioning entry\n",
    "        identifier = itemID.lower()\n",
    "        identity = [l for l in identifier] + rating + polarity\n",
    "\n",
    "        # add conditionining entry to each entry\n",
    "        formatted = [entry for entry in entries]\n",
    "\n",
    "        if printDebug:\n",
    "            print(\"ENTRY:\",dataset[itemID][i])\n",
    "            print(\"IDENTITY:\",identity)\n",
    "\n",
    "        for i in range(len(formatted)-1):\n",
    "            # add the conditioning variable to the input. the output value does not have the conditioning variable.\n",
    "            reviews.append([identity + formatted[i], formatted[i+1]])\n",
    "            if printDebug:\n",
    "                print(reviews[-1][0], \"->\", reviews[-1][1])\n",
    "        if printDebug:\n",
    "            break\n",
    "            \n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTRY: {'reviewerID': 'AA8JH8LD2H4P9', 'asin': '7214047977', 'reviewerName': 'Claudia J. Frier', 'helpful': [3, 4], 'reviewText': 'This fits my 7\" kindle fire hd perfectly! I love it. It even has a slot for a stylus. The kindle is velcroed in so it\\'s nice and secure. Very glad I bought this!', 'overall': 5.0, 'summary': 'love it', 'unixReviewTime': 1354665600, 'reviewTime': '12 5, 2012'}\n",
      "IDENTITY: ['7', '2', '1', '4', '0', '4', '7', '9', '7', '7', 'rating_5.0', 'polarity_-0.1']\n",
      "['7', '2', '1', '4', '0', '4', '7', '9', '7', '7', 'rating_5.0', 'polarity_-0.1', '<sos>', '<summary>', 'love', 'it', '</summary>'] -> ['<sos>', '<text>', 'this', 'fits', 'my', '7\"', 'kindle', 'fire', 'hd', 'perfectly', '!', '</text>']\n",
      "['7', '2', '1', '4', '0', '4', '7', '9', '7', '7', 'rating_5.0', 'polarity_-0.1', '<sos>', '<text>', 'this', 'fits', 'my', '7\"', 'kindle', 'fire', 'hd', 'perfectly', '!', '</text>'] -> ['<sos>', '<text>', 'i', 'love', 'it', '.', '</text>']\n",
      "['7', '2', '1', '4', '0', '4', '7', '9', '7', '7', 'rating_5.0', 'polarity_-0.1', '<sos>', '<text>', 'i', 'love', 'it', '.', '</text>'] -> ['<sos>', '<text>', 'it', 'even', 'has', 'a', 'slot', 'for', 'a', 'stylus', '.', '</text>']\n",
      "['7', '2', '1', '4', '0', '4', '7', '9', '7', '7', 'rating_5.0', 'polarity_-0.1', '<sos>', '<text>', 'it', 'even', 'has', 'a', 'slot', 'for', 'a', 'stylus', '.', '</text>'] -> ['<sos>', '<text>', 'the', 'kindle', 'is', 'velcroed', 'in', 'so', 'it', \"'\", 's', 'nice', 'and', 'secure', '.', '</text>']\n",
      "['7', '2', '1', '4', '0', '4', '7', '9', '7', '7', 'rating_5.0', 'polarity_-0.1', '<sos>', '<text>', 'the', 'kindle', 'is', 'velcroed', 'in', 'so', 'it', \"'\", 's', 'nice', 'and', 'secure', '.', '</text>'] -> ['<sos>', '<text>', 'very', 'glad', 'i', 'bought', 'this', '!', '</text>', '<eor>', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "datasetKeys = list(dataset.keys())\n",
    "example_set = handleItem(datasetKeys[params['example_item_id']],printDebug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"reference\": {\n",
      "    \"asin\": \"7214047977\",\n",
      "    \"helpful\": [\n",
      "      3,\n",
      "      4\n",
      "    ],\n",
      "    \"overall\": 5.0,\n",
      "    \"reviewText\": \"This fits my 7\\\" kindle fire hd perfectly! I love it. It even has a slot for a stylus. The kindle is velcroed in so it's nice and secure. Very glad I bought this!\",\n",
      "    \"reviewTime\": \"12 5, 2012\",\n",
      "    \"reviewerID\": \"AA8JH8LD2H4P9\",\n",
      "    \"reviewerName\": \"Claudia J. Frier\",\n",
      "    \"summary\": \"love it\",\n",
      "    \"unixReviewTime\": 1354665600\n",
      "  },\n",
      "  \"result\": [\n",
      "    [\n",
      "      [\n",
      "        \"7\",\n",
      "        \"2\",\n",
      "        \"1\",\n",
      "        \"4\",\n",
      "        \"0\",\n",
      "        \"4\",\n",
      "        \"7\",\n",
      "        \"9\",\n",
      "        \"7\",\n",
      "        \"7\",\n",
      "        \"rating_5.0\",\n",
      "        \"polarity_-0.1\",\n",
      "        \"<sos>\",\n",
      "        \"<summary>\",\n",
      "        \"love\",\n",
      "        \"it\",\n",
      "        \"</summary>\"\n",
      "      ],\n",
      "      [\n",
      "        \"<sos>\",\n",
      "        \"<text>\",\n",
      "        \"this\",\n",
      "        \"fits\",\n",
      "        \"my\",\n",
      "        \"7\\\"\",\n",
      "        \"kindle\",\n",
      "        \"fire\",\n",
      "        \"hd\",\n",
      "        \"perfectly\",\n",
      "        \"!\",\n",
      "        \"</text>\"\n",
      "      ]\n",
      "    ],\n",
      "    [\n",
      "      [\n",
      "        \"7\",\n",
      "        \"2\",\n",
      "        \"1\",\n",
      "        \"4\",\n",
      "        \"0\",\n",
      "        \"4\",\n",
      "        \"7\",\n",
      "        \"9\",\n",
      "        \"7\",\n",
      "        \"7\",\n",
      "        \"rating_5.0\",\n",
      "        \"polarity_-0.1\",\n",
      "        \"<sos>\",\n",
      "        \"<text>\",\n",
      "        \"this\",\n",
      "        \"fits\",\n",
      "        \"my\",\n",
      "        \"7\\\"\",\n",
      "        \"kindle\",\n",
      "        \"fire\",\n",
      "        \"hd\",\n",
      "        \"perfectly\",\n",
      "        \"!\",\n",
      "        \"</text>\"\n",
      "      ],\n",
      "      [\n",
      "        \"<sos>\",\n",
      "        \"<text>\",\n",
      "        \"i\",\n",
      "        \"love\",\n",
      "        \"it\",\n",
      "        \".\",\n",
      "        \"</text>\"\n",
      "      ]\n",
      "    ],\n",
      "    [\n",
      "      [\n",
      "        \"7\",\n",
      "        \"2\",\n",
      "        \"1\",\n",
      "        \"4\",\n",
      "        \"0\",\n",
      "        \"4\",\n",
      "        \"7\",\n",
      "        \"9\",\n",
      "        \"7\",\n",
      "        \"7\",\n",
      "        \"rating_5.0\",\n",
      "        \"polarity_-0.1\",\n",
      "        \"<sos>\",\n",
      "        \"<text>\",\n",
      "        \"i\",\n",
      "        \"love\",\n",
      "        \"it\",\n",
      "        \".\",\n",
      "        \"</text>\"\n",
      "      ],\n",
      "      [\n",
      "        \"<sos>\",\n",
      "        \"<text>\",\n",
      "        \"it\",\n",
      "        \"even\",\n",
      "        \"has\",\n",
      "        \"a\",\n",
      "        \"slot\",\n",
      "        \"for\",\n",
      "        \"a\",\n",
      "        \"stylus\",\n",
      "        \".\",\n",
      "        \"</text>\"\n",
      "      ]\n",
      "    ],\n",
      "    [\n",
      "      [\n",
      "        \"7\",\n",
      "        \"2\",\n",
      "        \"1\",\n",
      "        \"4\",\n",
      "        \"0\",\n",
      "        \"4\",\n",
      "        \"7\",\n",
      "        \"9\",\n",
      "        \"7\",\n",
      "        \"7\",\n",
      "        \"rating_5.0\",\n",
      "        \"polarity_-0.1\",\n",
      "        \"<sos>\",\n",
      "        \"<text>\",\n",
      "        \"it\",\n",
      "        \"even\",\n",
      "        \"has\",\n",
      "        \"a\",\n",
      "        \"slot\",\n",
      "        \"for\",\n",
      "        \"a\",\n",
      "        \"stylus\",\n",
      "        \".\",\n",
      "        \"</text>\"\n",
      "      ],\n",
      "      [\n",
      "        \"<sos>\",\n",
      "        \"<text>\",\n",
      "        \"the\",\n",
      "        \"kindle\",\n",
      "        \"is\",\n",
      "        \"velcroed\",\n",
      "        \"in\",\n",
      "        \"so\",\n",
      "        \"it\",\n",
      "        \"'\",\n",
      "        \"s\",\n",
      "        \"nice\",\n",
      "        \"and\",\n",
      "        \"secure\",\n",
      "        \".\",\n",
      "        \"</text>\"\n",
      "      ]\n",
      "    ],\n",
      "    [\n",
      "      [\n",
      "        \"7\",\n",
      "        \"2\",\n",
      "        \"1\",\n",
      "        \"4\",\n",
      "        \"0\",\n",
      "        \"4\",\n",
      "        \"7\",\n",
      "        \"9\",\n",
      "        \"7\",\n",
      "        \"7\",\n",
      "        \"rating_5.0\",\n",
      "        \"polarity_-0.1\",\n",
      "        \"<sos>\",\n",
      "        \"<text>\",\n",
      "        \"the\",\n",
      "        \"kindle\",\n",
      "        \"is\",\n",
      "        \"velcroed\",\n",
      "        \"in\",\n",
      "        \"so\",\n",
      "        \"it\",\n",
      "        \"'\",\n",
      "        \"s\",\n",
      "        \"nice\",\n",
      "        \"and\",\n",
      "        \"secure\",\n",
      "        \".\",\n",
      "        \"</text>\"\n",
      "      ],\n",
      "      [\n",
      "        \"<sos>\",\n",
      "        \"<text>\",\n",
      "        \"very\",\n",
      "        \"glad\",\n",
      "        \"i\",\n",
      "        \"bought\",\n",
      "        \"this\",\n",
      "        \"!\",\n",
      "        \"</text>\",\n",
      "        \"<eor>\",\n",
      "        \"<eos>\"\n",
      "      ]\n",
      "    ]\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "identity = example_set[0][0][:example_set[0][0].index(\"<sos>\")]\n",
    "\n",
    "example_tag = {\"reference\":dataset[datasetKeys[params['example_item_id']]][0],\n",
    "               \"result\":example_set}\n",
    "print(json.dumps(example_tag, indent=2, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63001\n"
     ]
    }
   ],
   "source": [
    "print(len(datasetKeys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processItems(func, args, n_processes = 7):\n",
    "    p = Pool(n_processes)\n",
    "    res_list = []\n",
    "    with tqdm(total = len(args)) as pbar:\n",
    "        for i, res in enumerate(p.imap_unordered(func, args)):\n",
    "            pbar.update()\n",
    "            res_list.append(res)\n",
    "    pbar.close()\n",
    "    p.close()\n",
    "    p.join()\n",
    "    return res_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 3938/3938 [00:32<00:00, 122.34it/s]\n"
     ]
    }
   ],
   "source": [
    "reviews = processItems(handleItem,datasetKeys[::params['datasetReduction']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Reviews:\n",
      "Training: 3150 \t\tValidation: 788\n",
      "Sequences:\n",
      "Training: 582471 \tValidation: 145102\n"
     ]
    }
   ],
   "source": [
    "datasetSize = len(reviews)\n",
    "trainRatio = int(datasetSize * params['trainPortion'])\n",
    "\n",
    "train = reviews[:trainRatio]\n",
    "validation = reviews[trainRatio:]\n",
    "\n",
    "print(\"Num Reviews:\")\n",
    "print(\"Training:\", len(train), \"\\t\\tValidation:\",len(validation))\n",
    "\n",
    "# now we need to flatten train and validation.\n",
    "trainents = []\n",
    "for review in train:\n",
    "    trainents += [entry for entry in review]\n",
    "valents = []\n",
    "for review in validation:\n",
    "    valents += [entry for entry in review]\n",
    "    \n",
    "train = trainents\n",
    "validation = valents\n",
    "\n",
    "print(\"Sequences:\")\n",
    "print(\"Training:\",len(train),\"\\tValidation:\",len(validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['b', '0', '0', '0', '0', '0', 'j', '1', 'u', 'b', 'rating_5.0', 'polarity_0.0', '<sos>', '<summary>', 'kb', 'at', 'to', 'ps/2', 'adapter', '</summary>'], ['<sos>', '<text>', 'the', 'package', 'arrived', 'in', 'a', 'timely', 'fashion', 'and', 'in', 'good', 'shape', '.', '</text>']]\n"
     ]
    }
   ],
   "source": [
    "# get the number of itemIDs\n",
    "for row in train:\n",
    "    print(row)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting ID's of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the throughput of the model, we should reduce the embedding size. Here we'll look at all the words and keep track ones that exist. We'll make a reduced word2id based on this set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcounts = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsetting Reviews..\n",
      "We now have 582471 reviews.\n"
     ]
    }
   ],
   "source": [
    "# here we reduce the size of the dataset so we can debug our model.\n",
    "print(\"Subsetting Reviews..\")\n",
    "print(\"We now have\", len(train), \"reviews.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 582471/582471 [00:10<00:00, 54668.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# get word frequency for words in training data\n",
    "for row in tqdm(train):\n",
    "    for sequences in row:\n",
    "        for word in sequences:\n",
    "            word = str(word)\n",
    "            if word not in wordcounts:\n",
    "                wordcounts[word] = 0\n",
    "            wordcounts[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get words that are not in the glove dataset\n",
    "knowns   = [word for word in wordcounts if word in glove]\n",
    "unknowns = [word for word in wordcounts if word not in glove]\n",
    "# sort words by their frequency\n",
    "wordOrder = list(sorted(knowns, key=lambda x: wordcounts[x], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43000 96066\n"
     ]
    }
   ],
   "source": [
    "print(len(knowns), len(unknowns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordOrder = wordOrder[:params['vocabularyLimit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [glove[word] for word in wordOrder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in unknowns:\n",
    "    if (\"rating\" in word) or (\"polarity\" in word):\n",
    "        try:\n",
    "            part = word.split(\"_\")\n",
    "            if part[1] == \"-0.0\":\n",
    "                part[1] = \"0.0\"\n",
    "            weight = glove[part[0]] + glove[part[1]]\n",
    "            wordOrder.append(word)\n",
    "            weights.append(weight)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionaries for constant time referencing\n",
    "id2word = {idx: w for (idx, w) in enumerate(wordOrder)}\n",
    "word2id = {w: idx for (idx, w) in enumerate(wordOrder)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lim = len(word2id)\n",
    "\n",
    "# add <sos> (start of sequence)\n",
    "weights.append(glove['sos'])\n",
    "word2id['<sos>'] = lim\n",
    "id2word[lim] = ['<sos>']\n",
    "lim += 1\n",
    "\n",
    "# add <eos> (end of sequence)\n",
    "weights.append(glove['eos'])\n",
    "word2id['<eos>'] = lim\n",
    "id2word[lim] = '<eos>'\n",
    "lim += 1\n",
    "\n",
    "\n",
    "gloveDimension = params['gloveDimension']\n",
    "\n",
    "sorWeight = np.random.normal(0,0.5,gloveDimension)\n",
    "weights.append(sorWeight)\n",
    "word2id['<summary>'] = lim\n",
    "id2word[lim] = '<summary>'\n",
    "lim += 1\n",
    "\n",
    "sorWeight = np.random.normal(0,0.5,gloveDimension)\n",
    "weights.append(sorWeight)\n",
    "word2id['</summary>'] = lim\n",
    "id2word[lim] = '</summary>'\n",
    "lim += 1\n",
    "\n",
    "sorWeight = np.random.normal(0,0.5,gloveDimension)\n",
    "weights.append(sorWeight)\n",
    "word2id['<text>'] = lim\n",
    "id2word[lim] = '<text>'\n",
    "lim += 1\n",
    "\n",
    "sorWeight = np.random.normal(0,0.5,gloveDimension)\n",
    "weights.append(sorWeight)\n",
    "word2id['</text>'] = lim\n",
    "id2word[lim] = '</text>'\n",
    "lim += 1\n",
    "\n",
    "\n",
    "# add <unk> (unknown token)\n",
    "weights.append(glove['unk'])\n",
    "word2id['<unk>'] = lim\n",
    "id2word[lim] = '<unk>'\n",
    "\n",
    "# add <pad> \n",
    "id2word[len(word2id)] = \"<pad>\"\n",
    "word2id[\"<pad>\"] = len(word2id)\n",
    "weights.append(np.random.normal(0,0,gloveDimension))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.normal(0,0,gloveDimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordToID(word,corp=word2id):\n",
    "    if word in corp:\n",
    "        return corp[word]\n",
    "    return corp['<unk>']\n",
    "\n",
    "def IDToWord(id,corp=id2word, ref=word2id):\n",
    "    if id in corp:\n",
    "        return corp[id]\n",
    "    return corp[ref['<unk>']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 582471/582471 [00:07<00:00, 76180.29it/s] \n",
      "100%|ââââââââââ| 145102/145102 [00:01<00:00, 93946.82it/s]\n"
     ]
    }
   ],
   "source": [
    "# convert words to their id's in the review.\n",
    "def entriesToWordIDs(group):\n",
    "    return [[[wordToID(word) for word in seq] for seq in row] for row in tqdm(group)]\n",
    "    \n",
    "train = entriesToWordIDs(train)\n",
    "validation = entriesToWordIDs(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The longest sequence in our dataset is 7141 tokens long.\n"
     ]
    }
   ],
   "source": [
    "sizes = {}\n",
    "for i in range(len(train)):\n",
    "    row = train[i]\n",
    "    for seq in row:\n",
    "        length = len(seq)\n",
    "        if length not in sizes:\n",
    "            sizes[length] = []\n",
    "        sizes[length].append(i)\n",
    "\n",
    "seqlengths = list(sorted(sizes.keys(), key=lambda x: len(sizes[x]), reverse=True))\n",
    "print(\"The longest sequence in our dataset is\",max(seqlengths),\"tokens long.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<text> they are listed in order of most inputs first , and more powerful amps first . . . * * * * * * * * * * * * * * * * * * * <unk> <unk> power , 2 channels <unk> , 1 khz @ 1 % thd . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> , 1 khz @ 10 % thd . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> power . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> , <unk> @ 1 % thd . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> harmonic distortion @ 1 khz rated power . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 0 . 3 % input sensitivity @ 1 khz , <unk> rated <unk> 1 , aux 2 , cd , usb . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 . <unk> response . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> signal to noise ratio @ 1 khz , <unk> rated <unk> 1 , aux 2 , cd , usb . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> <unk> . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . + <unk> , <unk> . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . + <unk> , <unk> requirement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> ac <unk> ac <unk> fuse . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . 5a , <unk> fast-acting , <unk> , inches ( mm ) <unk> . . . . . . . . . . . . . . . . 8 . 27 x 2 . 72 x 5 . 39 ( 210 x 69 x 137 ) weight , lbs ( kg ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 . 73 ( 2 . 6 ) * * * * * * * * * * * * * * * * * * * <unk> <unk> power , 2 channels <unk> , 1 khz @ 1 % thd . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> , 1 khz @ 10 % thd . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> power . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> , <unk> @ 1 % thd . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 . <unk> harmonic distortion @ 1 khz rated power . . . . . . . . . . . . . . . . . . . . . . . . . . . 0 . 3 % input sensitivity @ 1 khz , <unk> rated <unk> 1 , aux 2 , cd , usb . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 . <unk> response . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> signal to noise ratio @ 1 khz , <unk> rated <unk> 1 , aux 2 , cd , usb . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> <unk> . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . + <unk> , <unk> . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . + <unk> , <unk> requirement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> ac <unk> ac <unk> fuse . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . 5a , <unk> fast-acting , <unk> , inches ( mm ) <unk> . . . . . . . . . . . . . . . . 7 . 48 x 2 . 87 x 5 . 39 ( 190 x 73 x 137 ) weight , lbs ( kg ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 . 07 ( 2 . 3 ) * * * * * * * * * * * * * * * * * * * <unk> 23 <unk> power , 2 channels <unk> , 1 khz @ 1 % thd . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> , 1 khz @ 10 % thd . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> power . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> , <unk> @ 1 % thd . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> harmonic distortion @ 1 khz rated power . . . . . . . . . . . . . . . . . . . . . . . . 0 . 3 % input sensitivity @ 1 khz , <unk> rated <unk> 1 , aux 2 , cd , usb . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 . <unk> response . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> signal to noise ratio @ 1 khz , <unk> rated <unk> 1 , aux 2 , cd , usb . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> <unk> . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . + <unk> , <unk> . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . + <unk> , <unk> requirement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> ac <unk> ac <unk> fuse . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1a , <unk> fast-acting , <unk> , inches ( mm ) <unk> . . . . . . . . . . . . . . . . 7 . 48 x 2 . 72 x 5 . 39 ( 190 x 69 x 137 ) weight , lbs ( kg ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 . 97 ( 1 . 8 ) * * * * * * * * * * * * * * * * * * * <unk> <unk> power , 2 channels <unk> , 1 khz @ 1 % thd . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> , 1 khz @ 10 % thd . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> power . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> , <unk> @ 1 % thd . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> harmonic distortion @ 1 khz rated power . . . . . . . . . . . . . . . . . . . . . . . . . 0 . 3 % input sensitivity @ 1 khz , <unk> rated powerline . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> response . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> signal to noise ratio @ 1 khz , <unk> rated powerline . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> <unk> . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . + <unk> , <unk> . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . + <unk> , <unk> requirement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> ac <unk> ac <unk> fuse . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . 5 a , <unk> fast-acting , <unk> , inches ( mm ) <unk> . . . . . . . . . . . . . . . . 8 . 27 x 2 . 72 x 5 . 39 ( 210 x 69 x 137 ) weight , lbs ( kg ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 . 32 ( 2 . 42 ) * * * * * * * * * * * * * * * * * * * <unk> <unk> power , 2 channels <unk> , 1 khz @ 1 % thd . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> , 1 khz @ 10 % thd . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> power . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> , <unk> @ 1 % thd . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 . <unk> harmonic distortion @ 1 khz rated power . . . . . . . . . . . . . . . . . . . . . . 0 . 3 % input sensitivity @ 1 khz , <unk> rated powerline . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> response . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> signal to noise ratio @ 1 khz , <unk> rated powerline . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> <unk> . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . + <unk> , <unk> . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . + <unk> , <unk> requirement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> ac <unk> ac <unk> fuse . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . 5a , <unk> fast-acting , <unk> , inches ( mm ) <unk> . . . . . . . . . . . . . . . . . . 7 . 48 x 2 . 87 x 5 . 39 ( 190 x 73 x 137 ) weight , lbs ( kg ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 . 61 ( 2 . 09 ) * * * * * * * * * * * * * * * * * * * <unk> <unk> these specs are not as exacting as they normally are with quality <unk> power , 2 channels <unk> , 1 khz @ 1 % thd . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> , 1 khz @ 10 % thd . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> power . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> , <unk> @ 1 % thd . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 . <unk> harmonic distortion @ 1 khz rated power . . . . . . . . . . . . . . . . . . . . . 0 . 3 % input sensitivity @ 1 khz <unk> rated power . . . . . . . . . . . . . . . . . . . . . . . . <unk> response . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> signal to noise ratio . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> * * * * * * * * * * * * * * * * * * * <unk> <unk> <unk> ohms @ 1 % thd . . . 8w x 24 ohms @ 10 % thd . . . 10w x <unk> peak <unk> harmonic distortion ( thd ) . . . 0 . 3 % input signal to noise <unk> 1 , aux 2 , cd . . . <unk> . . . <unk> <unk> @ <unk> + <unk> ( <unk> ) <unk> - <unk> <unk> . 48 x 2 . 76 x 5 . <unk> ( 190 x 70 x 137 ) * * * * * * * * * * * * * * * * * * * <unk> <unk> these specs are not as exacting as they normally are with quality <unk> power , 2 channels <unk> , 1 khz @ 1 % thd . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 . <unk> , 1 khz @ 10 % thd . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 . <unk> power . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> , <unk> @ 1 % thd . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 . 5 <unk> harmonic distortion @ 1 khz rated power . . . . . . . . . . . . . . . . . . . . . . 0 . 3 % input sensitivity @ 1 khz <unk> rated power . . . . . . . . . . . . . . . . . . . . . . . . . <unk> response . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> signal to noise ratio . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . <unk> * </text> <unk> <eos>'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([IDToWord(x) for x in train[sizes[max(seqlengths)][0]][1][1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for charting purposes\n",
    "for i in range(1709):\n",
    "    if i not in sizes:\n",
    "        sizes[i] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot histogram of sequence lengths\n",
    "ents = [x for x in range(0,80)]\n",
    "bins = [len(sizes[x]) for x in ents]\n",
    "plt.bar(ents,bins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cutoff sequence length: 60\n"
     ]
    }
   ],
   "source": [
    "print(\"Cutoff sequence length:\", params['cutoff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|âââââ     | 253808/582471 [00:00<00:00, 2538076.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE: 582471 145102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 582471/582471 [00:00<00:00, 2490098.40it/s]\n",
      "100%|ââââââââââ| 145102/145102 [00:00<00:00, 2608319.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFTER: 553872 136909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def trimSeq(group, cutoff):\n",
    "    good = []\n",
    "    for i in tqdm(range(len(group))):\n",
    "        row = group[i]\n",
    "        if len(row[0]) <= cutoff and len(row[1]) <= cutoff:\n",
    "            good.append(i) \n",
    "    group = [group[x] for x in good]\n",
    "    return group\n",
    "\n",
    "#     return [[seq[:cutoff] for seq in row] for row in tqdm(group)]\n",
    "\n",
    "print(\"BEFORE:\", len(train), len(validation))\n",
    "train = trimSeq(train, params['cutoff'])\n",
    "validation = trimSeq(validation, params['cutoff'])\n",
    "print(\"AFTER:\", len(train), len(validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create container ready for use in dataset\n",
    "# we do not add padding here as we want to reduce storage size!\n",
    "container = {\n",
    "    'id2word' : id2word,\n",
    "    'word2id' : word2id,\n",
    "    'train' : train,\n",
    "    'validation': validation,\n",
    "    'weights' : np.matrix(weights),\n",
    "    'cutoff' : params['cutoff']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved! 110.1 MB\n"
     ]
    }
   ],
   "source": [
    "def convert_bytes(num):\n",
    "    \"\"\"\n",
    "    this function will convert bytes to MB.... GB... etc\n",
    "    \"\"\"\n",
    "    for x in ['bytes', 'KB', 'MB', 'GB', 'TB']:\n",
    "        if num < 1024.0:\n",
    "            return \"%3.1f %s\" % (num, x)\n",
    "        num /= 1024.0\n",
    "        \n",
    "# save the dataset to a pickle file.\n",
    "output = open(params['datasetFile'], 'wb')\n",
    "pickle.dump(container, output)\n",
    "output.close()\n",
    "\n",
    "# save dataset preprocessing parameters\n",
    "params['example_filtering'] = example_tag\n",
    "param_jsonpath = 'dataset_parameters.json'\n",
    "with open(param_jsonpath, 'w') as outfile:\n",
    "    json.dump(params, outfile)\n",
    "    \n",
    "print(\"Saved!\", convert_bytes(os.stat(params['datasetFile']).st_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sequence lengths for train and validation data\n",
    "trainx = [x[0] for x in train]\n",
    "trainy = [x[1] for x in train]\n",
    "valx   = [x[0] for x in validation]\n",
    "valy   = [x[1] for x in validation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vad_utils import batchData\n",
    "\n",
    "device = \"cpu\"\n",
    "batchsize = 32\n",
    "trainx_p = batchData(trainx, word2id['<pad>'], device, batchsize, params['cutoff'])\n",
    "trainy_p = batchData(trainy, word2id['<pad>'], device, batchsize, params['cutoff'])\n",
    "valx_p = batchData(valx, word2id['<pad>'], device, batchsize, params['cutoff'])\n",
    "valy_p = batchData(valy, word2id['<pad>'], device, batchsize, params['cutoff'])\n",
    "\n",
    "train_p = (trainx_p, trainy_p)\n",
    "val_p = (valx_p, valy_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightshape = np.matrix(weights).shape\n",
    "weightshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in range(len(train_p[0])):\n",
    "    # load x, y from batch\n",
    "    entry_x, entry_y = train_p[0][batch], train_p[1][batch]\n",
    "    # sepeate data from sentence lengths\n",
    "    y_outs, y_seqs = entry_y\n",
    "    \n",
    "    # get y_length\n",
    "    y_len = len(y_outs[0])\n",
    "    \n",
    "    num_classes = weightshape[0]\n",
    "    batch_size = y_outs.shape[0]\n",
    "    \n",
    "    loss = nn.BCEWithLogitsLoss()\n",
    "    sig =nn.Sigmoid()\n",
    "    \n",
    "    # iterate through the words in y\n",
    "    for w in range(y_len):\n",
    "        # get indexes of future words\n",
    "        labels = y_outs[:,w:].long().unsqueeze(2)\n",
    "        print(\"LABELS:\",labels.shape)\n",
    "        print(\"Y:\", y_outs[:,w:].shape)\n",
    "        \n",
    "        print(labels[0].unique())\n",
    "        \n",
    "        \n",
    "        bug = torch.FloatTensor(batch_size, num_classes).zero_()\n",
    "        bug.scatter_(1, y_outs[:,w:], 1)\n",
    "        print(\"BUG:\", bug.shape)\n",
    "\n",
    "        print(\"YES:\",(bug[0] > 0).max())\n",
    "#         print(labels)\n",
    "        # set up bag of words container\n",
    "        bow = torch.FloatTensor(batch_size, y_len-w, num_classes).zero_()\n",
    "        print(\"BOW BASE:\", bow.shape)\n",
    "        # create SBOW\n",
    "        bow.scatter_(2, labels, 1)\n",
    "        # sum by dimension and limit values between 0 and 1\n",
    "        bow = torch.sum(bow, dim=1).clamp(0,1)\n",
    "#         print(bow[0])\n",
    "        print(bow[0])\n",
    "        print(\"BOW:\",bow.shape)\n",
    "              \n",
    "        print(\"SAME?:\",torch.all(bug.eq(bow)).item() == 1)\n",
    "        \n",
    "        \n",
    "        # generate some random matrix of the same shape\n",
    "        guess = torch.rand(batch_size, num_classes)\n",
    "        guess = sig(guess)\n",
    "        err = loss(guess,bug)\n",
    "        print(err)\n",
    "        err = loss(guess,bow)\n",
    "        print(err)\n",
    "        print()\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
