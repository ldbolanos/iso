{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "import bcolz\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import math\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "# plotting\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from vad import batchData\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "\"\"\"\n",
    "Set seed #\n",
    "\"\"\"\n",
    "seed = 1337\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "def loadDataset(path = '../Datasets/Reviews/dataset_ready.pkl'):\n",
    "    return pickle.load(open(path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading parameters.. Done.\n",
      "Loading dataset.. Done.\n",
      "Converting dataset weights into tensors.. Done.\n",
      "Batching Data.. Done.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading parameters..\", end=\" \")\n",
    "batchSize  = 64\n",
    "iterations = 1\n",
    "learningRate = 0.0001\n",
    "bidirectionalEncoder = True\n",
    "device = \"cpu\"\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Done.\")\n",
    "\n",
    "print(\"Loading dataset..\", end=\" \")\n",
    "dataset = loadDataset()\n",
    "# setup store parameters\n",
    "id2word = dataset['id2word']\n",
    "word2id = dataset['word2id']\n",
    "weightMatrix = dataset['weights']\n",
    "train = dataset['train']\n",
    "validation = dataset['validation']\n",
    "cutoff = dataset['cutoff']\n",
    "paddingID = word2id['<pad>']\n",
    "print(\"Done.\")\n",
    "\n",
    "print(\"Converting dataset weights into tensors..\", end=\" \")\n",
    "# convert dataset into tensors\n",
    "weightMatrix = torch.tensor(weightMatrix, dtype=torch.float)\n",
    "print(\"Done.\")\n",
    "\n",
    "# batching data\n",
    "print(\"Batching Data..\",end=\" \")\n",
    "\n",
    "# shuffle data rows\n",
    "# random.shuffle(train)\n",
    "random.shuffle(validation)\n",
    "\n",
    "# trainx = [x[0] for x in train]\n",
    "# trainy = [x[1] for x in train]\n",
    "valx = [x[0] for x in validation]\n",
    "valy = [x[1] for x in validation]\n",
    "\n",
    "# shuffle data row\n",
    "\n",
    "# trainx = batchData(trainx, paddingID, device, batchSize, cutoff)\n",
    "# trainy = batchData(trainy, paddingID, device, batchSize, cutoff)\n",
    "valx = batchData(valx, paddingID, device, batchSize, cutoff)\n",
    "valy = batchData(valy, paddingID, device, batchSize, cutoff)\n",
    "\n",
    "traindata = (trainx, trainy)\n",
    "valdata= (valx, valy)\n",
    "print(\"Done.\")\n",
    "\n",
    "# setup variables for model components initialisation\n",
    "maxReviewLength = cutoff\n",
    "vocabularySize = len(id2word)\n",
    "embeddingDim = weightMatrix.shape[1]\n",
    "\n",
    "embedding_shape = weightMatrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Attn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d3c79d79868c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlatentSize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvad\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBackwards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPrior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initialising model components..\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Attn'"
     ]
    }
   ],
   "source": [
    "hiddenSize = 500\n",
    "latentSize = 400\n",
    "\n",
    "from vad import Encoder, Decoder, Attn, Backwards, Prior, Inference, loss_function\n",
    "\n",
    "print(\"Initialising model components..\", end=\" \")\n",
    "\n",
    "modelEncoder = Encoder(weightMatrix, vocabularySize,\n",
    "                       paddingID, hiddenSize, bidirectionalEncoder).to(device)\n",
    "# modelAttention = Attention(maxLength=maxReviewLength).to(device)\n",
    "# modelAttention = Attn(hiddenSize, bidirectionalEncoder).to(device)\n",
    "modelBackwards = Backwards(weightMatrix, vocabularySize,\n",
    "                           paddingID, hiddenSize, bidirectionalEncoder).to(device)\n",
    "# modelInference = Inference(\n",
    "    hiddenSize, latentSize, bidirectionalEncoder).to(device)\n",
    "# modelPrior = Prior(hiddenSize, latentSize, bidirectionalEncoder).to(device)\n",
    "modelDecoder = Decoder(weightMatrix, vocabularySize,\n",
    "                       paddingID, batchSize, maxReviewLength, hiddenSize, latentSize, bidirectionalEncoder).to(device)\n",
    "criterion = nn.NLLLoss(ignore_index=paddingID)\n",
    "print(\"Done.\")\n",
    "\n",
    "# load models\n",
    "print(\"Loading model weights..\", end=\" \")\n",
    "modelEncoder.load_state_dict(torch.load(os.path.join(filepath,'encoder.pth')))\n",
    "modelAttention.load_state_dict(torch.load(os.path.join(filepath,'attention.pth')))\n",
    "modelBackwards.load_state_dict(torch.load(os.path.join(filepath,'backwards.pth')))\n",
    "modelInference.load_state_dict(torch.load(os.path.join(filepath,'inference.pth')))\n",
    "modelPrior.load_state_dict(torch.load(os.path.join(filepath,'prior.pth')))\n",
    "modelDecoder.load_state_dict(torch.load(os.path.join(filepath,'decoder.pth')))\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(x,\n",
    "             xLength,\n",
    "             y,\n",
    "             yLength,\n",
    "             encoder,\n",
    "             attention,\n",
    "             backwards,\n",
    "             inference,\n",
    "             prior,\n",
    "             decoder,\n",
    "             criterion\n",
    "            ):\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    # initalise input and target lengths\n",
    "    inputLength = x[0].size(0)\n",
    "    targetLength = y[0].size(0)\n",
    "    batchSize = x.shape[0]\n",
    "\n",
    "    # set up encoder computation\n",
    "    encoderHidden = encoder.initHidden(batchSize).to(device)\n",
    "    backwardHidden = backwards.initHidden(batchSize).to(device)\n",
    "    \n",
    "    # set up encoder outputs\n",
    "    encoderOutputs, encoderHidden = encoder(x, encoderHidden, xLength)\n",
    "\n",
    "    # compute backwards outputs\n",
    "    backwardOutput, backwardHidden = backwards(torch.flip(\n",
    "        y, [0, 1]), yLength, backwardHidden)\n",
    "\n",
    "    # set up the variables for decoder computation\n",
    "    decoderInput = torch.tensor([[word2id[\"<sos>\"]]] * batchSize, dtype=torch.long, device=device)\n",
    "    \n",
    "    decoderHidden = encoderHidden[-1]\n",
    "    decoderOutput = None\n",
    "    decoderOutputs = []\n",
    "    \n",
    "    # Run through the decoder one step at a time. This seems to be common practice across\n",
    "    # all of the seq2seq based implementations I've come across on GitHub.\n",
    "    for t in range(yLength[0]):\n",
    "        # get the context vector c\n",
    "        c = attention(encoderOutputs, decoderHidden)\n",
    "        \n",
    "        # compute the prior layer\n",
    "        z_prior, _, _ = prior(decoderHidden, c)\n",
    "        \n",
    "        # compute the output of each decoder state\n",
    "        DecoderOut = decoder(decoderInput, c, z_prior, decoderHidden)\n",
    "        \n",
    "        # update variables\n",
    "        decoderOutput, decoderHidden = DecoderOut\n",
    "        decoderOutputs.append(decoderOutput)\n",
    "\n",
    "        # feed this output to the next input\n",
    "        decoderInput = y[:,t]\n",
    "#         decoderInput = decoderOutput.argmax(1)\n",
    "#         print(y[:,t].shape, decoderInput.shape)\n",
    "#         print(decoderOutput.argmax(1))\n",
    "        decoderHidden = decoderHidden.squeeze(0)\n",
    "        \n",
    "#     loss = loss.item()/targetLength\n",
    "        \n",
    "    return decoderOutputs, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateModel(batched_data,\n",
    "                   encoder,\n",
    "                   backward,\n",
    "                   attention,\n",
    "                   inference,\n",
    "                   prior,\n",
    "                   decoder,\n",
    "                   criterion,\n",
    "                   id2word,\n",
    "                  ):\n",
    "    \n",
    "    encoder.eval()\n",
    "    backward.eval()\n",
    "    attention.eval()\n",
    "    inference.eval()\n",
    "    prior.eval()\n",
    "    decoder.eval()\n",
    "    numbatches = len(batched_data)\n",
    "    for batch in tqdm(range(0,3)):\n",
    "        # each batch is composed of the \n",
    "        # reviews, and a sentence length.\n",
    "        x, xLength = batched_data[0][batch][0], batched_data[0][batch][1]\n",
    "        y, yLength = batched_data[1][batch][0], batched_data[1][batch][1]\n",
    "        \n",
    "        outputs, losses = evaluate(x,\n",
    "                                   xLength,\n",
    "                                   y,\n",
    "                                   yLength,\n",
    "                                   encoder,\n",
    "                                   attention,\n",
    "                                   backward,\n",
    "                                   inference,\n",
    "                                   prior,\n",
    "                                   decoder,\n",
    "                                   criterion)\n",
    "        \n",
    "        print(y.shape)\n",
    "        reference = convertRealID2Word(id2word,y)\n",
    "        words = convertDecoderID2Word(id2word,outputs)\n",
    "\n",
    "        for i in range(len(reference)):\n",
    "            print(\"REFERENCE:\", reference[i])\n",
    "            print(\"MODEL:    \",words[i])\n",
    "            print()\n",
    "        \n",
    "        print(\"LOSS:\", losses)\n",
    "#         break\n",
    "\n",
    "def convertRealID2Word(id2word, y):\n",
    "    entries = [[id2word[x.item()] for x in y[entry].cpu()] for entry in range(len(y))]\n",
    "    for i in range(len(entries)):\n",
    "        entries[i] = \" \".join(entries[i][12:])\n",
    "        entries[i] = entries[i].replace(\"<pad> \", \"\")\n",
    "#         entries[i] = entries[i][43:]\n",
    "    return entries\n",
    "        \n",
    "def convertDecoderID2Word(id2word, outputs):\n",
    "    entries = []\n",
    "    for batch_line in outputs:\n",
    "        entry = [torch.argmax(batch_line[i]).cpu().item() for i in range(len(batch_line))]\n",
    "        entries.append([id2word[i] for i in entry])\n",
    "     \n",
    "    words = []\n",
    "    for i in range(len(outputs[0])):\n",
    "#         line = \"\".join([entries[j][i] for j in range(0,12)])\n",
    "\n",
    "        line = \" \".join([entries[j][i] for j in range(12,len(entries))])\n",
    "#         line = line.replace(\" ' \", \"'\")\n",
    "#         line = line.replace(\" ) \", \")\")\n",
    "#         line = line.replace(\" . \", \".\")\n",
    "#         line = line.replace(\" , \", \", \")\n",
    "#         line = line.replace(\" ( \", \"(\")\n",
    "        words.append(line)\n",
    "    return words\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = evaluateModel(traindata,\n",
    "                   modelEncoder,\n",
    "                   modelBackwards,\n",
    "                   modelAttention,\n",
    "                   modelInference,\n",
    "                   modelPrior,\n",
    "                   modelDecoder,\n",
    "                   criterion,\n",
    "                   id2word\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
