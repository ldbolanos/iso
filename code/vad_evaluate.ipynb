{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "import bcolz\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import math\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "# plotting\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from vad_utils import batchData\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hiddenSize': 350, 'latentSize': 300, 'batchSize': 32, 'iterations': 20, 'learningRate': 0.0001, 'gradientClip': 1, 'useBOW': True, 'bidirectionalEncoder': True, 'reduction': 4, 'device': 'cuda', 'useLatent': True}\n"
     ]
    }
   ],
   "source": [
    "model_path = \"models/20190412 18-08-14\"\n",
    "param_path = os.path.join(model_path,\"model_parameters.json\")\n",
    "with open(param_path) as json_file:  \n",
    "    params = json.load(json_file)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Set seed #\n",
    "\"\"\"\n",
    "seed = 1337\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "def loadDataset(path = '../Datasets/Reviews/dataset_ready.pkl'):\n",
    "    return pickle.load(open(path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading parameters.. Done.\n",
      "Loading dataset.. Done.\n",
      "Converting dataset weights into tensors.. Done.\n",
      "Batching Data.. Done.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading parameters..\", end=\" \")\n",
    "batchSize  = 32\n",
    "iterations = 1\n",
    "bidirectionalEncoder = params['bidirectionalEncoder']\n",
    "# device = \"cpu\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Done.\")\n",
    "\n",
    "print(\"Loading dataset..\", end=\" \")\n",
    "dataset = loadDataset()\n",
    "# setup store parameters\n",
    "id2word = dataset['id2word']\n",
    "word2id = dataset['word2id']\n",
    "weightMatrix = dataset['weights']\n",
    "train = dataset['train']\n",
    "validation = dataset['validation']\n",
    "cutoff = dataset['cutoff']\n",
    "paddingID = word2id['<pad>']\n",
    "print(\"Done.\")\n",
    "\n",
    "print(\"Converting dataset weights into tensors..\", end=\" \")\n",
    "# convert dataset into tensors\n",
    "weightMatrix = torch.tensor(weightMatrix, dtype=torch.float)\n",
    "print(\"Done.\")\n",
    "\n",
    "# batching data\n",
    "print(\"Batching Data..\",end=\" \")\n",
    "\n",
    "random.shuffle(validation)\n",
    "\n",
    "trainx = [x[0] for x in train]\n",
    "trainy = [x[1] for x in train]\n",
    "valx = [x[0] for x in validation]\n",
    "valy = [x[1] for x in validation]\n",
    "\n",
    "trainx = batchData(trainx, paddingID, device, batchSize, cutoff)\n",
    "trainy = batchData(trainy, paddingID, device, batchSize, cutoff)\n",
    "valx = batchData(valx, paddingID, device, batchSize, cutoff)\n",
    "valy = batchData(valy, paddingID, device, batchSize, cutoff)\n",
    "\n",
    "traindata = (trainx, trainy)\n",
    "valdata = (valx, valy)\n",
    "print(\"Done.\")\n",
    "\n",
    "# setup variables for model components initialisation\n",
    "maxReviewLength = cutoff\n",
    "vocabularySize = len(id2word)\n",
    "embeddingDim = weightMatrix.shape[1]\n",
    "\n",
    "embedding_shape = weightMatrix.shape\n",
    "\n",
    "# setup additional variables\n",
    "hiddenSize = params['hiddenSize']\n",
    "latentSize = params['latentSize']\n",
    "# setup embeddiing\n",
    "\n",
    "embedding = nn.Embedding(\n",
    "        num_embeddings=vocabularySize,\n",
    "        embedding_dim=embeddingDim,\n",
    "        padding_idx=paddingID,\n",
    "    _weight=weightMatrix\n",
    "    ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising model components.. Done.\n",
      "Loading model weights.. Done.\n"
     ]
    }
   ],
   "source": [
    "from vad import Encoder, Decoder, loss_function\n",
    "print(\"Initialising model components..\", end=\" \")\n",
    "modelEncoder = Encoder(embedding, vocabularySize,\n",
    "                       paddingID, hiddenSize, bidirectionalEncoder).to(device)\n",
    "\n",
    "modelDecoder = Decoder(embedding, vocabularySize,\n",
    "                       paddingID, batchSize, maxReviewLength, hiddenSize, latentSize, bidirectionalEncoder).to(device)\n",
    "\n",
    "criterion = nn.NLLLoss(ignore_index=paddingID)\n",
    "\n",
    "\n",
    "print(\"Done.\")\n",
    "\n",
    "# load models\n",
    "print(\"Loading model weights..\", end=\" \")\n",
    "modelEncoder.load_state_dict(torch.load(os.path.join(model_path,'encoder.pth')))\n",
    "modelDecoder.load_state_dict(torch.load(os.path.join(model_path,'decoder.pth')))\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(x,\n",
    "             xLength,\n",
    "             y,\n",
    "             yLength,\n",
    "             encoder,\n",
    "             decoder,\n",
    "             device,\n",
    "             criterion,\n",
    "             word2id\n",
    "            ):\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    # initalise input and target lengths\n",
    "    inputLength = x[0].size(0)\n",
    "    targetLength = y[0].size(0)\n",
    "    batchSize = x.shape[0]\n",
    "\n",
    "    # set up encoder computation\n",
    "    encoderHidden = encoder.initHidden(batchSize).to(device)\n",
    "    \n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    \n",
    "    # set up encoder outputs\n",
    "    encoderOutputs, encoderHidden = encoder(x, encoderHidden, xLength)\n",
    "\n",
    "    # set up the variables for decoder computation\n",
    "    decoderInput = torch.tensor([word2id[\"<sos>\"]] * batchSize, dtype=torch.long, device=device)\n",
    "    \n",
    "    decoderHidden = encoderHidden[-1]\n",
    "    decoderOutput = None\n",
    "    decoderOutputs = []\n",
    "    \n",
    "    # Run through the decoder one step at a time. This seems to be common practice across\n",
    "    # all of the seq2seq based implementations I've come across on GitHub.\n",
    "    for t in range(yLength[0]):\n",
    "        # compute the output of each decoder state\n",
    "        decoderOutput, decoderHidden = decoder(decoderInput, encoderOutputs, xLength, decoderHidden, device, back=None)\n",
    "\n",
    "        decoderOutputs.append(decoderOutput)\n",
    "\n",
    "        decoderInput = decoderOutput.argmax(1)\n",
    "        decoderHidden = decoderHidden.squeeze(0)\n",
    "        \n",
    "    return decoderOutputs, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from train_vad import evalVAD as evaluate\n",
    "def evaluateModel(batched_data,\n",
    "                   encoder,\n",
    "                   decoder,\n",
    "                   criterion,\n",
    "                   id2word,\n",
    "                  ):\n",
    "    \n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    numbatches = len(batched_data)\n",
    "    for batch in tqdm(range(0,3)):\n",
    "        # each batch is composed of the \n",
    "        # reviews, and a sentence length.\n",
    "        x, xLength = batched_data[0][batch][0], batched_data[0][batch][1]\n",
    "        y, yLength = batched_data[1][batch][0], batched_data[1][batch][1]\n",
    "        \n",
    "        outputs, losses = evaluate(x,\n",
    "                                   xLength,\n",
    "                                   y,\n",
    "                                   yLength,\n",
    "                                   encoder,\n",
    "                                   decoder,\n",
    "                                   device,\n",
    "                                   criterion,\n",
    "                                   word2id)\n",
    "        break\n",
    "    return x, y, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "x, y, outputs = evaluateModel(traindata,\n",
    "                   modelEncoder,\n",
    "                   modelDecoder,\n",
    "                   criterion,\n",
    "                   id2word\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertRealID2Word(id2word, y):\n",
    "    entries = [[id2word[x.item()] for x in y[entry].cpu()] for entry in range(len(y))]\n",
    "    for i in range(len(entries)):\n",
    "        entries[i] = \" \".join(entries[i])\n",
    "        entries[i] = entries[i].replace(\"<pad> \", \"\")\n",
    "#         entries[i] = entries[i][43:]\n",
    "    return entries\n",
    "        \n",
    "def convertDecoderID2Word(id2word, outputs):\n",
    "    entries = []\n",
    "    for batch_line in outputs:\n",
    "        entry = [torch.argmax(batch_line[i]).cpu().item() for i in range(len(batch_line))]\n",
    "        entries.append([id2word[i] for i in entry])\n",
    "     \n",
    "    words = []\n",
    "    for i in range(len(outputs[0])):\n",
    "        tokens = [entries[j][i] for j in range(len(entries))]\n",
    "        # find the eos token\n",
    "        try:\n",
    "            tokenpos = tokens.index(\"<eos>\")\n",
    "        except:\n",
    "            tokenpos = len(tokens)\n",
    "        # remove extra eos tokens and padding values if they exist.\n",
    "        words.append(\" \".join(tokens[:tokenpos+1]))\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT: b 0 0 0 0 0 j 1 u b rating_5.0 polarity_0.0 <unk> he wanted to use one of them with his new pc that has usb inputs only ( i had previously bought him a ps/2 keyboard to usb adapter so he could use his * other * beloved , only slightly newer , keyboard . ) <eos> <pad>\n",
      "REFERENCE: <unk> he wanted to use one of them with his new pc that has usb inputs only ( i had previously bought him a ps/2 keyboard to usb adapter so he could use his * other * beloved , only slightly newer , keyboard . ) <eos> <pad>\n",
      "MODEL:     <unk> 'm a happy with this product . <eos>\n",
      "\n",
      "INPUT: b 0 0 0 0 0 j 1 u b rating_5.0 polarity_0.0 <unk> he called me asking if i could find a way to get his old \" big round plug \" keyboard with the new <unk> belkin <unk> adapter was just what he needed ( combined with the aforementioned <unk> adapter ) . <eos> <pad>\n",
      "REFERENCE: <unk> i had it sent to him and he called me a few days later , with delight , saying that the adapter worked perfectly , adding that he was astonished anyone still made components for devices as old as he was using . <eos> <pad>\n",
      "MODEL:     <unk> have been a happy with the <unk> . <eos>\n",
      "\n",
      "INPUT: b 0 0 0 0 0 j 1 u b rating_5.0 polarity_0.0 <unk> but he has also hung on to old keyboards he loves , including a pair of keyboards so old that they have the old pc / at style keyboard connector . <eos> <pad>\n",
      "REFERENCE: <unk> he called me asking if i could find a way to get his old \" big round plug \" keyboard with the new <unk> belkin <unk> adapter was just what he needed ( combined with the aforementioned <unk> adapter ) . <eos> <pad>\n",
      "MODEL:     <unk> 've a happy with the price . <eos>\n",
      "\n",
      "INPUT: 3 9 3 0 9 9 2 8 6 8 rating_5.0 polarity_0.0 <unk> make sure to note the orientation of the hd as it will only work one way ... easy to put the replacement hd in \" backwards \" . <eos> <pad>\n",
      "REFERENCE: <unk> but he has also hung on to old keyboards he loves , including a pair of keyboards so old that they have the old pc / at style keyboard connector . <eos> <pad>\n",
      "MODEL:     compiling the same is . . <eos>\n",
      "\n",
      "INPUT: b 0 0 0 0 0 j 1 u b rating_5.0 polarity_0.0 my favorite uncle , now in his 90s , hangs on to an old 386 pc running dos even after i bought him a new pc . <eos> <pad>\n",
      "REFERENCE: <unk> next , using a small pair of needle - nose pliers , grip the small ribbon cable gently , and push it back into it 's slot . <eos> <pad>\n",
      "MODEL:     <unk> 've a happy with the <unk> . <eos>\n",
      "\n",
      "INPUT: 3 9 3 0 9 9 2 8 6 8 rating_5.0 polarity_0.0 <unk> i had to use a piece of tape to secure the cable to the hd so it would n't come out . <eos> <pad>\n",
      "REFERENCE: <unk> make sure to note the orientation of the hd as it will only work one way ... easy to put the replacement hd in \" backwards \" . <eos> <pad>\n",
      "MODEL:     <unk> i have n't be a bit of the <unk> . <eos>\n",
      "\n",
      "INPUT: b 0 0 0 0 0 j 1 u b rating_4.0 polarity_0.0 if you want to use your newly purchased 1984 ibm model m keyboard with a modern computer using a ps/2 interface . <eos> <pad>\n",
      "REFERENCE: my favorite uncle , now in his 90s , hangs on to an old 386 pc running dos even after i bought him a new pc . <eos> <pad>\n",
      "MODEL:     <unk> 'm a happy with this product . <eos>\n",
      "\n",
      "INPUT: 3 9 3 0 9 9 2 8 6 8 rating_5.0 polarity_0.0 <unk> the only trouble i had was the cable would not stay in the hd for some reason . <eos> <pad>\n",
      "REFERENCE: awesome replacement for an ipod video 5th gen 30 gb hard drive , saved me the cost of buying a brand new ipod . <eos> <pad>\n",
      "MODEL:     <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> . <eos>\n",
      "\n",
      "INPUT: 3 9 3 0 9 9 2 8 6 8 rating_5.0 polarity_0.0 <unk> next , remove the bad hd by unplugging the ribbon cable on the hd side . <eos> <pad>\n",
      "REFERENCE: <unk> i had to use a piece of tape to secure the cable to the hd so it would n't come out . <eos> <pad>\n",
      "MODEL:     <unk> <unk> <unk> <unk> <unk> <unk> <unk> . <eos>\n",
      "\n",
      "INPUT: 3 9 3 0 9 9 2 8 6 8 rating_5.0 polarity_0.0 <unk> carefully pry apart the ipod with a small flat screwdriver and remove the smaller connector . <eos> <pad>\n",
      "REFERENCE: this article with all my expectations fulfilled recommend it because the packaging and jurisdiction <unk> correct , in addition to run <unk> <eos> <pad>\n",
      "MODEL:     <unk> <unk> <unk> <unk> <unk> <unk> <unk> . <eos>\n",
      "\n",
      "INPUT: 3 9 3 0 9 9 2 8 6 8 rating_5.0 polarity_0.0 <unk> if you have that indication , all you need is this <unk> repair was easy . <eos> <pad>\n",
      "REFERENCE: if you want to use your newly purchased 1984 ibm model m keyboard with a modern computer using a ps/2 interface . <eos> <pad>\n",
      "MODEL:     <unk> 's <unk> <unk> recommend the <eos>\n",
      "\n",
      "INPUT: 3 9 3 0 9 9 2 8 6 8 rating_5.0 polarity_0.0 <unk> i could hear the hd trying to spin up , but not reading properly . <eos> <pad>\n",
      "REFERENCE: <unk> the only trouble i had was the cable would not stay in the hd for some reason . <eos> <pad>\n",
      "MODEL:     <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> . <eos>\n",
      "\n",
      "INPUT: 3 9 3 0 9 9 2 8 6 8 rating_5.0 polarity_0.0 <unk> the ipod can now be placed on a table with both pieces open . <eos> <pad>\n",
      "REFERENCE: i even use this attached to about 2 more adapters and i have no keystroke loss or anything . <eos> <pad>\n",
      "MODEL:     <unk> 's <unk> is a happy . <eos>\n",
      "\n",
      "INPUT: 3 9 3 0 9 9 2 8 6 8 rating_5.0 polarity_0.0 brought back my ipod video 30 g back life , easy to replace . <eos> <pad>\n",
      "REFERENCE: <unk> next , remove the bad hd by unplugging the ribbon cable on the hd side . <eos> <pad>\n",
      "MODEL:     <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> . <eos>\n",
      "\n",
      "INPUT: b 0 0 0 0 0 j 1 u b rating_5.0 polarity_0.0 affordable and works for us keyboard nerds who love the old style keyboards . <eos> <pad>\n",
      "REFERENCE: <unk> carefully pry apart the ipod with a small flat screwdriver and remove the smaller connector . <eos> <pad>\n",
      "MODEL:     <unk> have been a happy with the <unk> . <eos>\n",
      "\n",
      "INPUT: 3 9 3 0 9 9 2 8 6 8 rating_5.0 polarity_0.0 <unk> it had the \" sad ipod face \" screen of death . <eos> <pad>\n",
      "REFERENCE: <unk> if you have that indication , all you need is this <unk> repair was easy . <eos> <pad>\n",
      "MODEL:     <unk> 's <unk> <unk> recommend the <eos>\n",
      "\n",
      "INPUT: 3 9 3 0 9 9 2 8 6 8 rating_5.0 polarity_0.0 a very easy replacement for a 5th gen ipod 30 g hd . <eos> <pad>\n",
      "REFERENCE: <unk> i could hear the hd trying to spin up , but not reading properly . <eos> <pad>\n",
      "MODEL:     <unk> <unk> <unk> <unk> <unk> <unk> <unk> . <eos>\n",
      "\n",
      "INPUT: b 0 0 0 0 0 j 1 u b rating_5.0 polarity_0.0 needed this to attach my model m keyboard to a kvm switch . <eos> <pad>\n",
      "REFERENCE: <unk> the ipod can now be placed on a table with both pieces open . <eos> <pad>\n",
      "MODEL:     <unk> have been a happy with the <unk> . <eos>\n",
      "\n",
      "INPUT: 3 9 3 0 9 9 2 8 6 8 rating_5.0 polarity_0.0 <unk> i purchased the ipod on ebay knowing it was damaged . <eos> <pad>\n",
      "REFERENCE: brought back my ipod video 30 g back life , easy to replace . <eos> <pad>\n",
      "MODEL:     <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> . <eos>\n",
      "\n",
      "INPUT: b 0 0 0 0 0 j 1 u b rating_5.0 polarity_0.0 the package arrived in a timely fashion and in good shape . <eos> <pad>\n",
      "REFERENCE: affordable and works for us keyboard nerds who love the old style keyboards . <eos> <pad>\n",
      "MODEL:     <unk> 'm a happy with the price . <eos>\n",
      "\n",
      "INPUT: 3 9 3 0 9 9 2 8 6 8 rating_5.0 polarity_0.0 <unk> replace with the new hd . <eos> <pad>\n",
      "REFERENCE: the adapter is exactly what i wanted and makes the connection i needed . <eos> <pad>\n",
      "MODEL:     <unk> <unk> <unk> <unk> <unk> <unk> <unk> . <eos>\n",
      "\n",
      "INPUT: b 0 0 0 0 0 j 1 u b rating_5.0 polarity_0.0 perfect , worked exactly as expected . <eos> <pad>\n",
      "REFERENCE: <unk> it had the \" sad ipod face \" screen of death . <eos> <pad>\n",
      "MODEL:     <unk> 've been happy with this product . <eos>\n",
      "\n",
      "INPUT: 3 9 3 0 9 9 2 8 6 8 rating_5.0 polarity_0.0 replaced 30 g ipod hd <eos> <pad>\n",
      "REFERENCE: a very easy replacement for a 5th gen ipod 30 g hd . <eos> <pad>\n",
      "MODEL:     <unk> i 've n't n't to . . <eos>\n",
      "\n",
      "INPUT: b 0 0 0 0 0 j 1 u b rating_5.0 polarity_0.0 <unk> he uses both . <eos> <pad>\n",
      "REFERENCE: needed this to attach my model m keyboard to a kvm switch . <eos> <pad>\n",
      "MODEL:     <unk> 'm a happy with this product . <eos>\n",
      "\n",
      "INPUT: b 0 0 0 0 0 j 1 u b rating_5.0 polarity_0.0 simple but does the job <eos> <pad>\n",
      "REFERENCE: <unk> i purchased the ipod on ebay knowing it was damaged . <eos> <pad>\n",
      "MODEL:     <unk> 've been happy with this product . <eos>\n",
      "\n",
      "INPUT: b 0 0 0 0 0 j 1 u b rating_5.0 polarity_0.0 kb at to ps/2 adapter <eos> <pad>\n",
      "REFERENCE: the package arrived in a timely fashion and in good shape . <eos> <pad>\n",
      "MODEL:     <unk> 've a happy with the <unk> . <eos>\n",
      "\n",
      "INPUT: 3 9 3 0 9 9 2 8 6 8 rating_5.0 polarity_0.0 good , cheap replacement <eos> <pad>\n",
      "REFERENCE: <unk> only hard part is to get the case opened . <eos> <pad>\n",
      "MODEL:     <unk> 's <unk> is a happy . <eos>\n",
      "\n",
      "INPUT: 3 9 3 0 9 9 2 8 6 8 rating_5.0 polarity_0.0 very nice item <eos> <pad>\n",
      "REFERENCE: so happy , typing on it now ! <eos> <pad>\n",
      "MODEL:     <unk> <unk> <unk> <unk> <unk> <unk> <unk> . <eos>\n",
      "\n",
      "INPUT: b 0 0 0 0 0 j 1 u b rating_5.0 polarity_0.0 works ! <eos> <pad>\n",
      "REFERENCE: <unk> replace with the new hd . <eos> <pad>\n",
      "MODEL:     <unk> have been happy with the <unk> . <eos>\n",
      "\n",
      "INPUT: b 0 0 0 0 0 j 1 u b rating_5.0 polarity_0.0 as expected <eos> <pad>\n",
      "REFERENCE: perfect , worked exactly as expected . <eos> <pad>\n",
      "MODEL:     <unk> have been a happy with the <unk> . <eos>\n",
      "\n",
      "INPUT: b 0 0 0 0 0 j 1 u b rating_4.0 polarity_0.0 very necessary <eos> <pad>\n",
      "REFERENCE: <unk> he uses both . <eos> <pad>\n",
      "MODEL:     <unk> 've a happy with the <unk> . <eos>\n",
      "\n",
      "INPUT: 3 9 3 0 9 9 2 8 6 8 rating_5.0 polarity_0.0 harddrive <eos> <pad>\n",
      "REFERENCE: :p <eos> <pad>\n",
      "MODEL:     <unk> <unk> <unk> . <eos>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "before = convertRealID2Word(id2word,x)\n",
    "reference = convertRealID2Word(id2word,y)\n",
    "words = convertDecoderID2Word(id2word,outputs)\n",
    "\n",
    "for i in range(len(reference)):\n",
    "    print(\"INPUT:\", before[i])\n",
    "    print(\"REFERENCE:\", reference[i])\n",
    "    print(\"MODEL:    \",words[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deletes models with no weights saved to them.\n",
    "import shutil\n",
    "import os\n",
    "for x in os.listdir('models'):\n",
    "    subpath = os.path.join('models', x)\n",
    "    if \"encoder.pth\" not in os.listdir(subpath):\n",
    "        print(\"bad\", subpath, os.listdir(subpath))\n",
    "        shutil.rmtree(subpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
