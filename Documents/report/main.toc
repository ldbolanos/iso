\babel@toc {english}{}
\contentsline {chapter}{\numberline {1}Introduction}{2}{chapter.2}
\contentsline {chapter}{\numberline {2}Literature Survey}{3}{chapter.3}
\contentsline {section}{\numberline {2.1}Text Generation}{3}{section.4}
\contentsline {section}{\numberline {2.2}Language Modelling}{4}{section.5}
\contentsline {section}{\numberline {2.3}Recurrent Neural Networks}{5}{section.9}
\contentsline {subsection}{\numberline {2.3.1}LSTMs and GRUs}{6}{subsection.14}
\contentsline {section}{\numberline {2.4}Autoencoders}{7}{section.17}
\contentsline {subsection}{\numberline {2.4.1}Variational Autoencoders}{8}{subsection.18}
\contentsline {subsection}{\numberline {2.4.2}Conditional Variational Autoencoders}{9}{subsection.24}
\contentsline {section}{\numberline {2.5}Related Work}{10}{section.26}
\contentsline {subsection}{\numberline {2.5.1}Sequence To Sequence}{10}{subsection.27}
\contentsline {subsubsection}{Attention Mechanism}{11}{section*.29}
\contentsline {subsection}{\numberline {2.5.2}Variational Sequence To Sequence}{12}{subsection.31}
\contentsline {subsection}{\numberline {2.5.3}Conditional Variational Sequence to Sequence}{12}{subsection.33}
\contentsline {chapter}{\numberline {3}Model}{13}{chapter.34}
\contentsline {section}{\numberline {3.1}Variational Autoregressive Decoders}{13}{section.35}
\contentsline {subsection}{\numberline {3.1.1}Encoder}{13}{subsection.37}
\contentsline {subsection}{\numberline {3.1.2}Backwards and Attention}{14}{subsection.39}
\contentsline {subsection}{\numberline {3.1.3}Decoder (Variational Autoregressive)}{14}{subsection.42}
\contentsline {subsubsection}{Inference and Prior Models}{15}{section*.44}
\contentsline {subsubsection}{Forward RNN}{15}{section*.47}
\contentsline {subsection}{\numberline {3.1.4}Auxillary Objective}{16}{subsection.49}
\contentsline {subsection}{\numberline {3.1.5}Learning Mechanism}{16}{subsection.51}
\contentsline {section}{\numberline {3.2}Optimisation Challenges}{17}{section.54}
\contentsline {subsection}{\numberline {3.2.1}KL Annealing}{17}{subsection.55}
\contentsline {subsection}{\numberline {3.2.2}Word Dropout}{17}{subsection.56}
\contentsline {subsection}{\numberline {3.2.3}Teacher Forcing}{18}{subsection.57}
\contentsline {chapter}{\numberline {4}Experimental Setup}{19}{chapter.58}
\contentsline {section}{\numberline {4.1}Datasets}{20}{section.60}
\contentsline {subsection}{\numberline {4.1.1}Amazon Reviews}{20}{subsection.61}
\contentsline {subsection}{\numberline {4.1.2}OpenSubtitles}{21}{subsection.83}
\contentsline {subsection}{\numberline {4.1.3}Penn TreeBank}{21}{subsection.88}
\contentsline {section}{\numberline {4.2}Hyperparameter Setup}{22}{section.93}
\contentsline {section}{\numberline {4.3}Measuring Performance}{23}{section.94}
\contentsline {subsection}{\numberline {4.3.1}BLEU and ROUGE}{23}{subsection.95}
\contentsline {chapter}{\numberline {5}Experimental Results}{24}{chapter.100}
\contentsline {section}{\numberline {5.1}NLL Loss}{24}{section.101}
\contentsline {section}{\numberline {5.2}KL Loss}{25}{section.103}
\contentsline {section}{\numberline {5.3}KL Ratio}{25}{section.105}
\contentsline {section}{\numberline {5.4}BLEU and ROUGE}{26}{section.107}
\contentsline {section}{\numberline {5.5}F1}{26}{section.109}
\contentsline {section}{\numberline {5.6}Output Variance}{27}{section.111}
\contentsline {section}{\numberline {5.7}Sampling Examples}{27}{section.112}
\contentsline {chapter}{\numberline {6}Evaluation and Future Work}{28}{chapter.113}
\contentsline {chapter}{\numberline {7}Conclusion}{29}{chapter.114}
\contentsline {section}{\numberline {7.1}KL Divergence Derivation}{33}{section.117}
