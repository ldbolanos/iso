\babel@toc {english}{}
\contentsline {chapter}{\numberline {1}Introduction}{2}{chapter.2}
\contentsline {chapter}{\numberline {2}Literature Survey}{3}{chapter.3}
\contentsline {section}{\numberline {2.1}Text Generation}{3}{section.4}
\contentsline {section}{\numberline {2.2}Language Modelling}{4}{section.5}
\contentsline {section}{\numberline {2.3}Recurrent Neural Networks}{5}{section.10}
\contentsline {subsection}{\numberline {2.3.1}LSTMs and GRUs}{7}{subsection.16}
\contentsline {section}{\numberline {2.4}Autoencoders}{7}{section.19}
\contentsline {subsection}{\numberline {2.4.1}Variational Autoencoders}{8}{subsection.20}
\contentsline {subsection}{\numberline {2.4.2}Conditional Variational Autoencoders}{9}{subsection.27}
\contentsline {section}{\numberline {2.5}Related Work}{10}{section.29}
\contentsline {subsection}{\numberline {2.5.1}Sequence To Sequence}{10}{subsection.30}
\contentsline {subsubsection}{Attention Mechanism}{11}{section*.32}
\contentsline {subsection}{\numberline {2.5.2}Variational Sequence To Sequence}{11}{subsection.34}
\contentsline {subsection}{\numberline {2.5.3}Conditional Variational Sequence to Sequence}{13}{subsection.36}
\contentsline {chapter}{\numberline {3}Model}{14}{chapter.38}
\contentsline {section}{\numberline {3.1}Variational Autoregressive Decoders}{14}{section.39}
\contentsline {subsection}{\numberline {3.1.1}Architecture}{14}{subsection.41}
\contentsline {subsubsection}{Encoder}{14}{section*.42}
\contentsline {subsubsection}{Backwards and Attention}{15}{section*.44}
\contentsline {subsubsection}{Decoder}{15}{section*.47}
\contentsline {subsubsection}{Inference and Prior Models}{16}{section*.49}
\contentsline {subsubsection}{Forward RNN}{16}{section*.52}
\contentsline {subsection}{\numberline {3.1.2}Auxillary Objective}{17}{subsection.54}
\contentsline {subsection}{\numberline {3.1.3}Learning Mechanism}{17}{subsection.56}
\contentsline {section}{\numberline {3.2}Optimisation Challenges}{17}{section.59}
\contentsline {subsection}{\numberline {3.2.1}KL Annealing}{18}{subsection.60}
\contentsline {subsection}{\numberline {3.2.2}Word Dropout}{18}{subsection.61}
\contentsline {chapter}{\numberline {4}Experimental Setup}{19}{chapter.62}
\contentsline {section}{\numberline {4.1}Datasets}{20}{section.67}
\contentsline {subsection}{\numberline {4.1.1}Amazon Reviews}{20}{subsection.68}
\contentsline {subsection}{\numberline {4.1.2}OpenSubtitles}{21}{subsection.90}
\contentsline {subsection}{\numberline {4.1.3}Penn TreeBank}{22}{subsection.95}
\contentsline {section}{\numberline {4.2}Training Setup}{23}{section.100}
\contentsline {section}{\numberline {4.3}Evaluation Measurements}{23}{section.101}
\contentsline {subsection}{\numberline {4.3.1}KL Ratio}{23}{subsection.102}
\contentsline {subsection}{\numberline {4.3.2}BLEU and ROUGE}{23}{subsection.103}
\contentsline {subsection}{\numberline {4.3.3}Semantic Similarity}{24}{subsection.108}
\contentsline {chapter}{\numberline {5}Experimental Results}{26}{chapter.109}
\contentsline {section}{\numberline {5.1}Model Optimisation}{26}{section.110}
\contentsline {subsection}{\numberline {5.1.1}NLL Loss}{26}{subsection.111}
\contentsline {subsection}{\numberline {5.1.2}KL Ratio}{27}{subsection.113}
\contentsline {section}{\numberline {5.2}Linguistic Analysis}{27}{section.115}
\contentsline {subsection}{\numberline {5.2.1}BLEU and ROUGE}{27}{subsection.116}
\contentsline {subsection}{\numberline {5.2.2}F1}{28}{subsection.119}
\contentsline {subsection}{\numberline {5.2.3}Output Variance}{29}{subsection.122}
\contentsline {subsection}{\numberline {5.2.4}Sampling Examples}{29}{subsection.124}
\contentsline {chapter}{\numberline {6}Evaluation and Future Work}{31}{chapter.126}
\contentsline {chapter}{\numberline {7}Conclusion}{32}{chapter.127}
\contentsline {chapter}{\numberline {8}Appendix}{36}{chapter.129}
\contentsline {section}{\numberline {8.1}KL Divergence Derivation}{36}{section.130}
