\babel@toc {english}{}
\contentsline {chapter}{\numberline {1}Literature Survey}{2}{chapter.2}
\contentsline {section}{\numberline {1.1}Artificial Data}{2}{section.3}
\contentsline {section}{\numberline {1.2}Text Generation}{2}{section.4}
\contentsline {section}{\numberline {1.3}Language Modelling}{2}{section.5}
\contentsline {section}{\numberline {1.4}Recurrent Neural Networks}{4}{section.9}
\contentsline {subsection}{\numberline {1.4.1}LSTMs and GRUs}{5}{subsection.13}
\contentsline {section}{\numberline {1.5}Autoencoders}{5}{section.16}
\contentsline {subsection}{\numberline {1.5.1}Variational Autoencoders}{6}{subsection.17}
\contentsline {section}{\numberline {1.6}Related Work}{7}{section.22}
\contentsline {subsection}{\numberline {1.6.1}Seq2Seq}{7}{subsection.23}
\contentsline {subsection}{\numberline {1.6.2}seq2seq with VAEs}{8}{subsection.25}
\contentsline {subsection}{\numberline {1.6.3}Seq2Seq with Attention}{8}{subsection.26}
\contentsline {subsection}{\numberline {1.6.4}Transformers}{9}{subsection.28}
\contentsline {subsubsection}{Self Attention}{9}{section*.30}
\contentsline {subsubsection}{Positionality Hack}{10}{section*.34}
\contentsline {subsection}{\numberline {1.6.5}Conditional Variational Autoencoders}{10}{subsection.35}
\contentsline {subsection}{\numberline {1.6.6}Variational Autoregressive Decoders}{11}{subsection.37}
\contentsline {subsubsection}{Encoder}{11}{section*.38}
\contentsline {subsubsection}{Backwards}{11}{section*.40}
\contentsline {subsubsection}{Attention}{11}{section*.42}
\contentsline {subsubsection}{Inference Model}{12}{section*.44}
\contentsline {subsubsection}{Prior Model}{12}{section*.46}
\contentsline {subsubsection}{Decoder (Variational Autoregressive)}{12}{section*.48}
\contentsline {subsubsection}{Auxillary Objective}{12}{section*.51}
\contentsline {subsubsection}{Learning Mechanism}{12}{section*.53}
\contentsline {subsubsection}{KL Divergence Derivation}{13}{section*.55}
\contentsline {chapter}{\numberline {2}Contribution}{14}{chapter.57}
\contentsline {section}{\numberline {2.1}Data Augmentation}{14}{section.58}
\contentsline {subsection}{\numberline {2.1.1}Embeddings}{15}{subsection.80}
\contentsline {subsection}{\numberline {2.1.2}Review Prepropressing}{15}{subsection.81}
\contentsline {subsection}{\numberline {2.1.3}Polarity Calculation}{15}{subsection.82}
\contentsline {subsection}{\numberline {2.1.4}Implementation}{15}{subsection.84}
\contentsline {section}{\numberline {2.2}Optimisation Challenges}{15}{section.85}
\contentsline {subsection}{\numberline {2.2.1}KL Annealing}{16}{subsection.86}
\contentsline {subsection}{\numberline {2.2.2}Word Dropout}{16}{subsection.87}
\contentsline {section}{\numberline {2.3}Testing Method}{16}{section.88}
\contentsline {subsection}{\numberline {2.3.1}Measuring Performance}{16}{subsection.89}
