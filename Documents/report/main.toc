\babel@toc {english}{}
\contentsline {chapter}{\numberline {1}Introduction}{2}{chapter.2}
\contentsline {chapter}{\numberline {2}Literature Survey}{3}{chapter.3}
\contentsline {section}{\numberline {2.1}Text Generation}{3}{section.4}
\contentsline {section}{\numberline {2.2}Language Modelling}{4}{section.5}
\contentsline {section}{\numberline {2.3}Recurrent Neural Networks}{5}{section.9}
\contentsline {subsection}{\numberline {2.3.1}LSTMs and GRUs}{6}{subsection.14}
\contentsline {section}{\numberline {2.4}Autoencoders}{7}{section.17}
\contentsline {subsection}{\numberline {2.4.1}Variational Autoencoders}{7}{subsection.18}
\contentsline {subsection}{\numberline {2.4.2}Conditional Variational Autoencoders}{9}{subsection.24}
\contentsline {section}{\numberline {2.5}Related Work}{10}{section.26}
\contentsline {subsection}{\numberline {2.5.1}Sequence To Sequence}{10}{subsection.27}
\contentsline {subsubsection}{Attention Mechanism}{11}{section*.29}
\contentsline {subsection}{\numberline {2.5.2}Variational Sequence To Sequence}{11}{subsection.31}
\contentsline {subsection}{\numberline {2.5.3}Conditional Variational Sequence to Sequence}{12}{subsection.33}
\contentsline {chapter}{\numberline {3}Model}{14}{chapter.35}
\contentsline {section}{\numberline {3.1}Variational Autoregressive Decoders}{14}{section.36}
\contentsline {subsection}{\numberline {3.1.1}Architecture}{15}{subsection.38}
\contentsline {subsubsection}{Encoder}{15}{section*.39}
\contentsline {subsubsection}{Backwards and Attention}{15}{section*.41}
\contentsline {subsubsection}{Decoder}{15}{section*.44}
\contentsline {subsubsection}{Inference and Prior Models}{16}{section*.46}
\contentsline {subsubsection}{Forward RNN}{16}{section*.49}
\contentsline {subsection}{\numberline {3.1.2}Auxillary Objective}{17}{subsection.51}
\contentsline {subsection}{\numberline {3.1.3}Learning Mechanism}{17}{subsection.53}
\contentsline {section}{\numberline {3.2}Optimisation Challenges}{17}{section.56}
\contentsline {subsection}{\numberline {3.2.1}KL Annealing}{18}{subsection.57}
\contentsline {subsection}{\numberline {3.2.2}Word Dropout}{18}{subsection.58}
\contentsline {chapter}{\numberline {4}Experimental Setup}{19}{chapter.59}
\contentsline {section}{\numberline {4.1}Datasets}{20}{section.62}
\contentsline {subsection}{\numberline {4.1.1}Amazon Reviews}{20}{subsection.63}
\contentsline {subsection}{\numberline {4.1.2}OpenSubtitles}{21}{subsection.85}
\contentsline {subsection}{\numberline {4.1.3}Penn TreeBank}{22}{subsection.90}
\contentsline {section}{\numberline {4.2}Training Setup}{22}{section.95}
\contentsline {subsection}{\numberline {4.2.1}Word Embeddings}{23}{subsection.96}
\contentsline {section}{\numberline {4.3}Evaluation Measurements}{23}{section.97}
\contentsline {subsection}{\numberline {4.3.1}KL Loss and KL Ratio}{23}{subsection.98}
\contentsline {subsection}{\numberline {4.3.2}BLEU and ROUGE}{23}{subsection.99}
\contentsline {subsection}{\numberline {4.3.3}Semantic Similarity}{24}{subsection.104}
\contentsline {chapter}{\numberline {5}Experimental Results}{25}{chapter.105}
\contentsline {section}{\numberline {5.1}Model Optimisation}{25}{section.106}
\contentsline {subsection}{\numberline {5.1.1}NLL Loss}{25}{subsection.107}
\contentsline {subsection}{\numberline {5.1.2}KL Loss}{26}{subsection.109}
\contentsline {subsection}{\numberline {5.1.3}KL Ratio}{26}{subsection.111}
\contentsline {section}{\numberline {5.2}Linguistic Analysis}{27}{section.113}
\contentsline {subsection}{\numberline {5.2.1}BLEU and ROUGE}{27}{subsection.114}
\contentsline {subsection}{\numberline {5.2.2}F1}{27}{subsection.116}
\contentsline {subsection}{\numberline {5.2.3}Output Variance}{28}{subsection.118}
\contentsline {subsection}{\numberline {5.2.4}Sampling Examples}{28}{subsection.120}
\contentsline {chapter}{\numberline {6}Evaluation and Future Work}{30}{chapter.122}
\contentsline {chapter}{\numberline {7}Conclusion}{32}{chapter.123}
\contentsline {chapter}{\numberline {8}Appendix}{36}{chapter.125}
\contentsline {section}{\numberline {8.1}KL Divergence Derivation}{36}{section.126}
